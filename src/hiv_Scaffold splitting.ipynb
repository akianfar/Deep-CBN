{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w71ntxmiP5Cs"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2mc3-OTP210",
    "outputId": "1bcf264f-343b-4610-b609-3c89f2b742f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 08:51:59.858696: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-27 08:51:59.863495: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-27 08:51:59.869711: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-27 08:51:59.881181: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-27 08:51:59.897946: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-27 08:51:59.903924: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-27 08:51:59.919210: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-27 08:52:00.823003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Skipped loading some Pytorch utilities, missing a dependency. No module named 'torch'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module requires PyTorch to be installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/finder/houjue/conda_envs/deep_cbn/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some PyTorch models, missing a dependency. No module named 'torch'\n",
      "No module named 'torch'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras import optimizers, layers, regularizers, metrics\n",
    "from tensorflow.keras.layers import (\n",
    "    Lambda, Input, Reshape, Activation, Concatenate, Dense, Dropout,\n",
    "    BatchNormalization, Conv1D, GlobalMaxPooling1D, LayerNormalization, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.tensorflow import Rearrange\n",
    "from deepchem.data import NumpyDataset\n",
    "from deepchem.splits import ScaffoldSplitter\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFGjtuURP7OE"
   },
   "source": [
    "### Cloning a GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-xDZ16oP-4J",
    "outputId": "ed8899b2-2a9e-4f4c-d520-e07eced6dba1"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/akianfar/Deep-CBN.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWrFzNjSQCtg"
   },
   "source": [
    "### Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "kXFLqk2vja5M",
    "outputId": "3e31a23d-130b-48c7-cfd4-bc76cd6c75bb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "smiles",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "activity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HIV_active",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "af0ca8f1-994c-411b-affc-72825efd2f91",
       "rows": [
        [
         "0",
         "CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)=[O+]2",
         "CI",
         "0"
        ],
        [
         "1",
         "C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3)CC(c3ccccc3)=[O+]2)[O+]=C(c2ccccc2)C1",
         "CI",
         "0"
        ],
        [
         "2",
         "CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21",
         "CI",
         "0"
        ],
        [
         "3",
         "Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1",
         "CI",
         "0"
        ],
        [
         "4",
         "O=S(=O)(O)CCS(=O)(=O)O",
         "CI",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>activity</th>\n",
       "      <th>HIV_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=S(=O)(O)CCS(=O)(=O)O</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles activity  HIV_active\n",
       "0  CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...       CI           0\n",
       "1  C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...       CI           0\n",
       "2                   CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21       CI           0\n",
       "3    Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1       CI           0\n",
       "4                             O=S(=O)(O)CCS(=O)(=O)O       CI           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Data/hiv.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AFxos0tgQC9s"
   },
   "outputs": [],
   "source": [
    "smiles = data['smiles']\n",
    "labels = data['HIV_active']\n",
    "\n",
    "# Dictionary to convert SMILES characters into numeric values\n",
    "smiles_dict = {\n",
    "    \"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2,\n",
    "    \"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6,\n",
    "    \"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43,\n",
    "    \"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13,\n",
    "    \"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50, \"T\": 17, \"W\": 51,\n",
    "    \"V\": 18, \"Y\": 52, \"[\": 53, \"Z\": 19, \"]\": 54, \"\\\\\": 20, \"a\": 55, \"c\": 56,\n",
    "    \"b\": 21, \"e\": 57, \"d\": 22, \"g\": 58, \"f\": 23, \"i\": 59, \"h\": 24, \"m\": 60,\n",
    "    \"l\": 25, \"o\": 61, \"n\": 26, \"s\": 62, \"r\": 27, \"u\": 63, \"t\": 28, \"y\": 64,\n",
    "    \" \": 65, \":\": 66, \",\": 67, \"p\": 68, \"j\": 69, \"*\": 70\n",
    "}\n",
    "\n",
    "def label_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
    "    X = np.zeros(MAX_SMI_LEN, dtype=int)\n",
    "    for i, ch in enumerate(line[:MAX_SMI_LEN]):\n",
    "        if ch in smi_ch_ind:\n",
    "            X[i] = smi_ch_ind[ch]\n",
    "    return X\n",
    "\n",
    "MAX_SMI_LEN = 100  # You can adjust this based on your needs\n",
    "XD = np.array([label_smiles(str(smi), MAX_SMI_LEN, smiles_dict) for smi in smiles])\n",
    "labels = labels.values\n",
    "\n",
    "# Convert to categorical\n",
    "XD = to_categorical(XD, num_classes=71)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qmjyj91JeXsG"
   },
   "source": [
    "# phaze1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A2VgoLaMQN0X",
    "outputId": "d183f5ed-45d0-496a-8aa7-9347ac07ec00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 08:52:03.885438: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_feature\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"model_feature\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ XDinput (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ XDinput (\u001b[38;5;33mInputLayer\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m71\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m9,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,496</span> (228.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m58,496\u001b[0m (228.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,496</span> (228.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m58,496\u001b[0m (228.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">217,026</span> (847.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m217,026\u001b[0m (847.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">215,490</span> (841.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m215,490\u001b[0m (841.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"interactionModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"interactionModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ XDinput (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ model_feature (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">58,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">217,026</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ XDinput (\u001b[38;5;33mInputLayer\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m71\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ model_feature (\u001b[38;5;33mFunctional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m58,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │       \u001b[38;5;34m217,026\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">275,522</span> (1.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m275,522\u001b[0m (1.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">273,986</span> (1.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m273,986\u001b[0m (1.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature model definition\n",
    "XDinput = Input(shape=(100, 71), name='XDinput')\n",
    "encode_smiles = Conv1D(filters=64, kernel_size=2, activation='relu', padding='valid', strides=1)(XDinput)  # (99,64)\n",
    "encode_smiles = Conv1D(filters=64, kernel_size=4, activation='relu', padding='valid', strides=1)(encode_smiles)  # (96,64)\n",
    "encode_smiles = Conv1D(filters=128, kernel_size=4, activation='relu', padding='valid', strides=1)(encode_smiles)  # (93,128)\n",
    "model_feature = Model(inputs=XDinput, outputs=encode_smiles, name='model_feature')\n",
    "model_feature.summary()\n",
    "\n",
    "# Prediction model definition\n",
    "input_extracted_feature = Input(shape=(93, 128))\n",
    "FC1 = Dense(512, activation='relu')(input_extracted_feature)\n",
    "FC1 = BatchNormalization()(FC1)\n",
    "FC2 = Dropout(0.1)(FC1)\n",
    "FC3 = Dense(256, activation='relu')(FC2)\n",
    "FC3 = BatchNormalization()(FC3)\n",
    "FC4 = Dropout(0.1)(FC3)\n",
    "FC5 = Dense(64, activation='relu')(FC4)\n",
    "predictions = Dense(2, activation='softmax')(FC5)\n",
    "model_pred = Model(inputs=input_extracted_feature, outputs=predictions)\n",
    "model_pred.summary()\n",
    "\n",
    "# Full model definition with added Pooling layer\n",
    "interaction_input = XDinput\n",
    "encoded_features = model_feature(interaction_input)  # Output: (None, 93, 128)\n",
    "predicted_output = model_pred(encoded_features)      # Output: (None, 93, 2)\n",
    "\n",
    "# Adding Pooling layer to reduce dimensionality\n",
    "pooled_output = GlobalAveragePooling1D()(predicted_output)  # Output: (None, 2)\n",
    "\n",
    "# Final model definition\n",
    "interactionModel = Model(inputs=interaction_input, outputs=pooled_output, name='interactionModel')\n",
    "interactionModel.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KW4Dc7MfQWbn"
   },
   "source": [
    "### BiFormer Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "C5EAZalFQWpH"
   },
   "outputs": [],
   "source": [
    "# Define custom layers for 1D processing\n",
    "class TopkRouting(layers.Layer):\n",
    "    def __init__(self, qk_dim, topk=16, qk_scale=None, param_routing=False, diff_routing=False):\n",
    "        super().__init__()\n",
    "        self.topk = topk\n",
    "        self.qk_dim = qk_dim\n",
    "        self.scale = qk_scale if qk_scale is not None else qk_dim**-0.5\n",
    "        self.diff_routing = diff_routing\n",
    "        if param_routing:\n",
    "            self.emb = layers.Dense(qk_dim)\n",
    "        else:\n",
    "            self.emb = lambda x: x\n",
    "        self.routing_act = lambda x, axis: tf.nn.softmax(x, axis=axis)\n",
    "\n",
    "    def call(self, query, key, training=None):\n",
    "        if not self.diff_routing:\n",
    "            query = tf.stop_gradient(query)\n",
    "            key = tf.stop_gradient(key)\n",
    "        query_hat = self.emb(query)\n",
    "        key_hat = self.emb(key)\n",
    "\n",
    "        attn_logit = tf.einsum('bnc,bqc->bnq', query_hat*self.scale, key_hat)  # Adjusted for 1D\n",
    "        topk_attn_logit, topk_index = tf.math.top_k(attn_logit, k=self.topk, sorted=True)\n",
    "        r_weight = self.routing_act(topk_attn_logit, axis=-1)\n",
    "        return r_weight, topk_index\n",
    "\n",
    "def tf_gather_kv(kv, r_idx):\n",
    "    n = tf.shape(kv)[0]\n",
    "    p2 = tf.shape(kv)[1]\n",
    "    c_kv = tf.shape(kv)[2]\n",
    "    topk = tf.shape(r_idx)[2]\n",
    "\n",
    "    batch_idx = tf.reshape(tf.range(n), [n, 1, 1])\n",
    "    batch_idx = tf.tile(batch_idx, [1, p2, topk])\n",
    "    p2_idx = tf.reshape(tf.range(p2), [1, p2, 1])\n",
    "    p2_idx = tf.tile(p2_idx, [n, 1, topk])\n",
    "\n",
    "    gather_indices = tf.stack([batch_idx, p2_idx, r_idx], axis=-1)\n",
    "    gathered = tf.gather_nd(kv, gather_indices)\n",
    "    return gathered  # Shape: (n, p2, topk, c_kv)\n",
    "\n",
    "class KVGather(layers.Layer):\n",
    "    def __init__(self, mul_weight='none'):\n",
    "        super().__init__()\n",
    "        assert mul_weight in ['none', 'soft', 'hard']\n",
    "        self.mul_weight = mul_weight\n",
    "\n",
    "    def call(self, r_idx, r_weight, kv, training=None):\n",
    "        topk_kv = tf_gather_kv(kv, r_idx)\n",
    "        if self.mul_weight == 'soft':\n",
    "            r_weight_exp = tf.expand_dims(tf.expand_dims(r_weight, -1), -1)\n",
    "            topk_kv = topk_kv * r_weight_exp\n",
    "        return topk_kv\n",
    "\n",
    "class QKVLinear(layers.Layer):\n",
    "    def __init__(self, dim, qk_dim, bias=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.qk_dim = qk_dim\n",
    "        self.qkv = layers.Dense(qk_dim + qk_dim + dim, use_bias=bias)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        qkv = self.qkv(x)\n",
    "        q, kv = tf.split(qkv, [self.qk_dim, self.qk_dim + self.dim], axis=-1)\n",
    "        return q, kv\n",
    "\n",
    "class BiLevelRoutingAttention(layers.Layer):\n",
    "    def __init__(self, dim, n_win=7, num_heads=8, qk_dim=None, qk_scale=None,\n",
    "                 kv_per_win=4, kv_downsample_ratio=4, kv_downsample_mode='identity',\n",
    "                 topk=4, param_attention=\"qkvo\", param_routing=False, diff_routing=False, soft_routing=False,\n",
    "                 side_dwconv=3, auto_pad=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.n_win = n_win\n",
    "        self.num_heads = num_heads\n",
    "        self.qk_dim = qk_dim if qk_dim is not None else dim\n",
    "        self.scale = qk_scale if qk_scale is not None else self.qk_dim**-0.5\n",
    "        self.topk = topk\n",
    "        self.param_routing = param_routing\n",
    "        self.diff_routing = diff_routing\n",
    "        self.soft_routing = soft_routing\n",
    "        self.auto_pad = auto_pad\n",
    "\n",
    "        # For 1D, we use Conv1D\n",
    "        if side_dwconv > 0:\n",
    "            self.lepe = layers.Conv1D(dim, kernel_size=side_dwconv, padding='same', activation='relu')\n",
    "        else:\n",
    "            self.lepe = lambda x: tf.zeros_like(x)\n",
    "\n",
    "        self.router = TopkRouting(qk_dim=self.qk_dim, topk=self.topk, qk_scale=self.scale,\n",
    "                                  param_routing=self.param_routing, diff_routing=self.diff_routing)\n",
    "\n",
    "        mul_weight = 'none'\n",
    "        if self.soft_routing:\n",
    "            mul_weight = 'soft'\n",
    "        self.kv_gather = KVGather(mul_weight=mul_weight)\n",
    "\n",
    "        if param_attention in ['qkvo', 'qkv']:\n",
    "            self.qkv = QKVLinear(self.dim, self.qk_dim)\n",
    "            if param_attention == 'qkvo':\n",
    "                self.wo = layers.Dense(self.dim)\n",
    "            else:\n",
    "                self.wo = lambda x: x\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported param_attention mode\")\n",
    "\n",
    "        self.attn_act = lambda x: tf.nn.softmax(x, axis=-1)\n",
    "        self.kv_down = lambda x: x  # identity for simplicity\n",
    "\n",
    "    def call(self, x, training=None, ret_attn_mask=False):\n",
    "        # Implementing full attention can be complex, so here we only keep the general structure\n",
    "        if ret_attn_mask:\n",
    "            return x, None, None, None\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class Attention(layers.Layer):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale if qk_scale is not None else head_dim**-0.5\n",
    "        self.qkv = layers.Dense(dim*3, use_bias=qkv_bias)\n",
    "        self.attn_drop = layers.Dropout(attn_drop)\n",
    "        self.proj = layers.Dense(dim)\n",
    "        self.proj_drop = layers.Dropout(proj_drop)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        batch_size, seq_length, dim = tf.unstack(tf.shape(x))\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = tf.split(qkv, 3, axis=-1)\n",
    "        q = rearrange(q, 'b s (h d) -> b h s d', h=self.num_heads)\n",
    "        k = rearrange(k, 'b s (h d) -> b h s d', h=self.num_heads)\n",
    "        v = rearrange(v, 'b s (h d) -> b h s d', h=self.num_heads)\n",
    "\n",
    "        attn = tf.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "        attn = tf.nn.softmax(attn, axis=-1)\n",
    "        attn = self.attn_drop(attn, training=training)\n",
    "        out = tf.einsum('bhij,bhjd->bhid', attn, v)\n",
    "        out = rearrange(out, 'b h s d -> b s (h d)')\n",
    "        out = self.proj(out)\n",
    "        out = self.proj_drop(out, training=training)\n",
    "        return out\n",
    "\n",
    "class AttentionLePE(layers.Layer):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0., side_dwconv=5):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale if qk_scale is not None else head_dim**-0.5\n",
    "        self.qkv = layers.Dense(dim*3, use_bias=qkv_bias)\n",
    "        self.attn_drop = layers.Dropout(attn_drop)\n",
    "        self.proj = layers.Dense(dim)\n",
    "        self.proj_drop = layers.Dropout(proj_drop)\n",
    "        if side_dwconv > 0:\n",
    "            self.lepe = layers.Conv1D(dim, kernel_size=side_dwconv, padding='same', activation='relu')\n",
    "        else:\n",
    "            self.lepe = lambda x: tf.zeros_like(x)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        lepe_out = self.lepe(x)\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = tf.split(qkv, 3, axis=-1)\n",
    "        q = rearrange(q, 'b s (h d) -> b h s d', h=self.num_heads)\n",
    "        k = rearrange(k, 'b s (h d) -> b h s d', h=self.num_heads)\n",
    "        v = rearrange(v, 'b s (h d) -> b h s d', h=self.num_heads)\n",
    "\n",
    "        attn = tf.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "        attn = tf.nn.softmax(attn, axis=-1)\n",
    "        attn = self.attn_drop(attn, training=training)\n",
    "        out = tf.einsum('bhij,bhjd->bhid', attn, v)\n",
    "        out = rearrange(out, 'b h s d -> b s (h d)')\n",
    "        out = out + lepe_out\n",
    "        out = self.proj(out)\n",
    "        out = self.proj_drop(out, training=training)\n",
    "        return out\n",
    "\n",
    "class PreNorm(layers.Layer):\n",
    "    def __init__(self, fn):\n",
    "        super(PreNorm, self).__init__()\n",
    "        self.norm = layers.LayerNormalization()\n",
    "        self.fn = fn\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return self.fn(self.norm(x), training=training)\n",
    "\n",
    "class MLP(layers.Layer):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = keras.Sequential([\n",
    "            layers.Dense(hidden_dim),\n",
    "            layers.Activation('gelu'),\n",
    "            layers.Dropout(rate=dropout),\n",
    "            layers.Dense(dim),\n",
    "            layers.Dropout(rate=dropout)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        return self.net(x, training=training)\n",
    "\n",
    "class DropPath(layers.Layer):\n",
    "    # Placeholder for DropPath, currently no-op\n",
    "    def __init__(self, drop_prob=0.):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        if (not training) or self.drop_prob == 0.:\n",
    "            return x\n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        random_tensor = keep_prob\n",
    "        random_tensor += tf.random.uniform(tf.shape(x), dtype=x.dtype)\n",
    "        binary_tensor = tf.floor(random_tensor)\n",
    "        return tf.divide(x, keep_prob) * binary_tensor\n",
    "\n",
    "class Block(layers.Layer):\n",
    "    def __init__(self, dim, drop_path=0.1, layer_scale_init_value=-1,\n",
    "                 num_heads=8, n_win=7, qk_dim=128, qk_scale=None,\n",
    "                 kv_per_win=8, kv_downsample_ratio=1, kv_downsample_mode='identity',\n",
    "                 topk=8, param_attention=\"qkvo\", param_routing=True, diff_routing=False, soft_routing=True,\n",
    "                 mlp_ratio=4, mlp_dwconv=False, side_dwconv=5, before_attn_dwconv=3, pre_norm=True, auto_pad=True):\n",
    "        super().__init__()\n",
    "        qk_dim = qk_dim or dim\n",
    "\n",
    "        # For 1D, we use Conv1D\n",
    "        if before_attn_dwconv > 0:\n",
    "            self.pos_embed = layers.Conv1D(dim, kernel_size=before_attn_dwconv, padding='same', activation='relu')\n",
    "        else:\n",
    "            self.pos_embed = lambda x: tf.zeros_like(x)\n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        if topk > 0:\n",
    "            self.attn = BiLevelRoutingAttention(dim=dim, num_heads=num_heads, n_win=n_win, qk_dim=qk_dim,\n",
    "                                               qk_scale=qk_scale, kv_per_win=kv_per_win, kv_downsample_ratio=kv_downsample_ratio,\n",
    "                                               kv_downsample_mode=kv_downsample_mode, topk=topk, param_attention=param_attention,\n",
    "                                               param_routing=param_routing, diff_routing=diff_routing, soft_routing=soft_routing,\n",
    "                                               side_dwconv=side_dwconv, auto_pad=auto_pad)\n",
    "        elif topk == -1:\n",
    "            self.attn = Attention(dim=dim, num_heads=num_heads, qk_scale=qk_scale)\n",
    "        elif topk == -2:\n",
    "            self.attn = AttentionLePE(dim=dim, num_heads=num_heads, qk_scale=qk_scale, side_dwconv=side_dwconv)\n",
    "        elif topk == 0:\n",
    "            # Pseudo attention\n",
    "            self.attn = keras.Sequential([\n",
    "                layers.Dense(dim),\n",
    "                layers.Conv1D(dim, kernel_size=5, padding='same', activation='relu'),\n",
    "                layers.Dense(dim)\n",
    "            ])\n",
    "\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        mlp_hidden_dim = int(mlp_ratio * dim)\n",
    "        mlp_layers = [layers.Dense(mlp_hidden_dim)]\n",
    "        if mlp_dwconv:\n",
    "            mlp_layers.append(layers.Conv1D(mlp_hidden_dim, kernel_size=3, padding='same', activation='relu'))\n",
    "        mlp_layers.append(layers.Activation('gelu'))\n",
    "        mlp_layers.append(layers.Dense(dim))\n",
    "        mlp_layers.insert(1, layers.Dropout(0.2)) # Add dropout after first Dense\n",
    "        mlp_layers.append(layers.Dropout(0.2))\n",
    "        self.mlp = keras.Sequential(mlp_layers)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else layers.Lambda(lambda x: x)\n",
    "\n",
    "        if layer_scale_init_value > 0:\n",
    "            self.use_layer_scale = True\n",
    "            self.gamma1 = self.add_weight(shape=(dim,),\n",
    "                                          initializer=tf.keras.initializers.Constant(layer_scale_init_value),\n",
    "                                          trainable=True)\n",
    "            self.gamma2 = self.add_weight(shape=(dim,),\n",
    "                                          initializer=tf.keras.initializers.Constant(layer_scale_init_value),\n",
    "                                          trainable=True)\n",
    "        else:\n",
    "            self.use_layer_scale = False\n",
    "\n",
    "        self.pre_norm = pre_norm\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        x = x + self.pos_embed(x)  # Add positional embedding\n",
    "\n",
    "        if self.pre_norm:\n",
    "            if self.use_layer_scale:\n",
    "                x = x + self.drop_path(self.gamma1 * self.attn(self.norm1(x), training=training), training=training)\n",
    "                x = x + self.drop_path(self.gamma2 * self.mlp(self.norm2(x), training=training), training=training)\n",
    "            else:\n",
    "                x = x + self.drop_path(self.attn(self.norm1(x), training=training), training=training)\n",
    "                x = x + self.drop_path(self.mlp(self.norm2(x), training=training), training=training)\n",
    "        else:\n",
    "            if self.use_layer_scale:\n",
    "                tmp = x + self.drop_path(self.gamma1 * self.attn(x, training=training), training=training)\n",
    "                x = self.norm1(tmp)\n",
    "                tmp = x + self.drop_path(self.gamma2 * self.mlp(x, training=training), training=training)\n",
    "                x = self.norm2(tmp)\n",
    "            else:\n",
    "                tmp = x + self.drop_path(self.attn(x, training=training), training=training)\n",
    "                x = self.norm1(tmp)\n",
    "                tmp = x + self.drop_path(self.mlp(x, training=training), training=training)\n",
    "                x = self.norm2(tmp)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k41fqbmrQxbV"
   },
   "source": [
    "# phaze2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "qFxfd5e4QdV3",
    "outputId": "3ffefc83-bb87-45ff-cb54-e4535be8d055"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/finder/houjue/conda_envs/deep_cbn/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'bi_level_routing_attention', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/mnt/finder/houjue/conda_envs/deep_cbn/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'bi_level_routing_attention_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">148,608</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">148,608</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ difference (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ difference[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block (\u001b[38;5;33mBlock\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m148,608\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_1 (\u001b[38;5;33mBlock\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m148,608\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ block[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ block_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m2\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ difference (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ difference[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">297,216</span> (1.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m297,216\u001b[0m (1.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">297,216</span> (1.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m297,216\u001b[0m (1.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameter settings for the block\n",
    "dim = 128\n",
    "num_heads = 8\n",
    "mlp_dim = 128 * 3\n",
    "depth = 2\n",
    "dim_head = 48\n",
    "\n",
    "# Create Phase 2 model\n",
    "input_phaz2 = Input(shape=(93, 128))\n",
    "\n",
    "processed_input = input_phaz2\n",
    "\n",
    "# Define transformer blocks\n",
    "transformer_block1 = Block(dim=dim, drop_path=0.2, num_heads=num_heads, topk=16, mlp_ratio=3)\n",
    "transformer_block2 = Block(dim=dim, drop_path=0.2, num_heads=num_heads, topk=16, mlp_ratio=3)\n",
    "\n",
    "# Apply the first transformer block\n",
    "transformer_output1 = transformer_block1(processed_input)\n",
    "# Compute the norm of the output along the last axis (preserving dimensions)\n",
    "transformer_output1 = Lambda(lambda x: tf.norm(x, axis=-1, keepdims=True))(transformer_output1)\n",
    "\n",
    "# Apply the second transformer block\n",
    "transformer_output2 = transformer_block2(processed_input)\n",
    "# Compute the norm of the output along the last axis (preserving dimensions)\n",
    "transformer_output2 = Lambda(lambda x: tf.norm(x, axis=-1, keepdims=True))(transformer_output2)\n",
    "\n",
    "# Combine the outputs of both transformer blocks along the last axis\n",
    "combined_outputs = Concatenate(axis=-1)([transformer_output1, transformer_output2])\n",
    "\n",
    "# Apply global average pooling to reduce the output to (batch_size, 2)\n",
    "pooled_outputs = GlobalAveragePooling1D()(combined_outputs)\n",
    "\n",
    "# Compute the difference between the two pooled outputs and reshape to (batch_size, 1)\n",
    "difference = Lambda(lambda x: tf.expand_dims(x[:, 0] - x[:, 1], axis=-1), name='difference')(pooled_outputs)\n",
    "\n",
    "# Apply sigmoid activation to normalize the output to the range [0, 1]\n",
    "condition_2 = Activation('sigmoid', name='activation_11')(difference)\n",
    "\n",
    "# Freeze the `model_feature` layers to prevent them from being trained\n",
    "model_feature.trainable = False\n",
    "\n",
    "# Define the complete model\n",
    "model_phaz2 = Model(inputs=input_phaz2, outputs=condition_2)\n",
    "model_phaz2.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcH6Y5x1e5OS"
   },
   "source": [
    "# phaze3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "F6DTjT17Q1W5",
    "outputId": "6bcfc3f8-eeee-418e-cddd-31ff826c0ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer_4 True\n",
      "model_feature False\n",
      "block_2 False\n",
      "block_3 False\n",
      "lambda_2 True\n",
      "lambda_3 True\n",
      "concatenate_1 True\n",
      "global_average_pooling1d_2 True\n",
      "dense_24 True\n",
      "batch_normalization_2 True\n",
      "dropout_10 True\n",
      "dense_25 True\n",
      "batch_normalization_3 True\n",
      "dropout_11 True\n",
      "dense_26 True\n",
      "dense_27 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/finder/houjue/conda_envs/deep_cbn/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'bi_level_routing_attention_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/mnt/finder/houjue/conda_envs/deep_cbn/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'bi_level_routing_attention_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ model_feature       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">58,496</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">148,608</span> │ model_feature[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">148,608</span> │ model_feature[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m71\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ model_feature       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m58,496\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_2 (\u001b[38;5;33mBlock\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m148,608\u001b[0m │ model_feature[\u001b[38;5;34m1\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_3 (\u001b[38;5;33mBlock\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m148,608\u001b[0m │ model_feature[\u001b[38;5;34m1\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ block_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ block_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m2\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m1,536\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m130\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">508,226</span> (1.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m508,226\u001b[0m (1.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150,978</span> (589.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m150,978\u001b[0m (589.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">357,248</span> (1.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m357,248\u001b[0m (1.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define new transformer blocks\n",
    "new_transformer_block = Block(dim=dim, drop_path=0.2, num_heads=num_heads, topk=16, mlp_ratio=3)\n",
    "new_transformer_block2 = Block(dim=dim, drop_path=0.2, num_heads=num_heads, topk=16, mlp_ratio=3)\n",
    "\n",
    "# Input for Phase 3\n",
    "XDinput_phaz3 = Input(shape=(100, 71))\n",
    "# Pass input through the feature extraction model\n",
    "model_feature_output = model_feature(XDinput_phaz3)  # Output shape: (93, 192)\n",
    "\n",
    "# Transformer blocks processing\n",
    "transformer_output1_phaz3 = new_transformer_block(model_feature_output)  # Output shape: (93, 192)\n",
    "# Compute the norm along the last axis, retaining dimensions\n",
    "transformer_output1_phaz3 = layers.Lambda(lambda x: tf.norm(x, axis=-1, keepdims=True))(transformer_output1_phaz3)  # Shape: (93, 1)\n",
    "\n",
    "transformer_output2_phaz3 = new_transformer_block2(model_feature_output)  # Output shape: (93, 192)\n",
    "# Compute the norm along the last axis, retaining dimensions\n",
    "transformer_output2_phaz3 = layers.Lambda(lambda x: tf.norm(x, axis=-1, keepdims=True))(transformer_output2_phaz3)  # Shape: (93, 1)\n",
    "\n",
    "# Combine the outputs of both transformer blocks\n",
    "concatenated_phaz3 = Concatenate(axis=-1)([transformer_output1_phaz3, transformer_output2_phaz3])  # Shape: (93, 2)\n",
    "\n",
    "# Freeze the weights of feature extractor and transformer blocks\n",
    "model_feature.trainable = False\n",
    "new_transformer_block.trainable = False\n",
    "new_transformer_block2.trainable = False\n",
    "\n",
    "# Apply global average pooling to reduce the dimensions to (batch_size, 2)\n",
    "pooled_phaz3 = GlobalAveragePooling1D()(concatenated_phaz3)  # Shape: (None, 2)\n",
    "\n",
    "# Fully connected layers\n",
    "FC1_phaz3 = Dense(512, activation='relu')(pooled_phaz3)\n",
    "FC1_phaz3 = BatchNormalization()(FC1_phaz3)\n",
    "FC2_phaz3 = Dropout(0.1)(FC1_phaz3)  # Increased dropout rate\n",
    "FC3_phaz3 = Dense(256, activation='relu')(FC2_phaz3)\n",
    "FC3_phaz3 = BatchNormalization()(FC3_phaz3)\n",
    "FC4_phaz3 = Dropout(0.1)(FC3_phaz3)  # Increased dropout rate\n",
    "FC5_phaz3 = Dense(64, activation='relu')(FC4_phaz3)\n",
    "\n",
    "# Final prediction layer with softmax activation\n",
    "predictions_phaz3 = Dense(2, activation='softmax')(FC5_phaz3)\n",
    "\n",
    "# Define the complete model for Phase 3\n",
    "model_phaz3 = Model(inputs=XDinput_phaz3, outputs=predictions_phaz3)\n",
    "\n",
    "# Print the name and trainable status of each layer\n",
    "for layer in model_phaz3.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "\n",
    "# Model summary\n",
    "model_phaz3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jF60_7QXQ4lB"
   },
   "outputs": [],
   "source": [
    "# Metrics for binary classification tasks\n",
    "METRICS_BINARY = [\n",
    "    metrics.BinaryAccuracy(name='accuracy'),  # Calculates accuracy for binary classification\n",
    "    metrics.AUC(name='auc'),  # Area Under the Curve (ROC AUC) metric\n",
    "]\n",
    "\n",
    "# Metrics for categorical (multi-class) classification tasks\n",
    "METRICS_CATEGORICAL = [\n",
    "    metrics.CategoricalAccuracy(name='accuracy'),  # Calculates accuracy for multi-class classification\n",
    "    metrics.Precision(name='precision'),  # Precision: TP / (TP + FP)\n",
    "    metrics.Recall(name='recall'),  # Recall: TP / (TP + FN)\n",
    "    metrics.AUC(name='auc'),  # Area Under the Curve (ROC AUC) metric\n",
    "    metrics.F1Score(average='macro', name='f1_score')  # F1 Score (macro-averaged): Harmonic mean of precision and recall\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBNS2iz6f9xP"
   },
   "source": [
    "# Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xcS3ex1TgCRK",
    "outputId": "7a3df7f6-88ae-459e-8e9d-fde383fd7d9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:52:05] Explicit valence for atom # 3 Al, 6, is greater than permitted\n",
      "[08:52:06] Explicit valence for atom # 5 B, 5, is greater than permitted\n",
      "[08:52:10] Explicit valence for atom # 16 Al, 9, is greater than permitted\n",
      "[08:52:12] Explicit valence for atom # 4 Al, 9, is greater than permitted\n",
      "[08:52:17] Explicit valence for atom # 12 Al, 7, is greater than permitted\n",
      "[08:52:17] Explicit valence for atom # 13 Al, 7, is greater than permitted\n",
      "[08:52:18] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:52:18] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:52:19] Explicit valence for atom # 6 Ge, 5, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 32901\n",
      "Number of test samples: 4106\n",
      "Epoch 1/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 181ms/step - accuracy: 0.6447 - auc: 0.6626 - f1_score: 0.4415 - loss: 0.6628 - precision: 0.6447 - recall: 0.6447\n",
      "Epoch 2/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.7256 - auc: 0.7663 - f1_score: 0.4814 - loss: 0.6162 - precision: 0.7256 - recall: 0.7256\n",
      "Epoch 3/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 185ms/step - accuracy: 0.7735 - auc: 0.8227 - f1_score: 0.5055 - loss: 0.6112 - precision: 0.7735 - recall: 0.7735\n",
      "Epoch 4/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.8437 - auc: 0.8885 - f1_score: 0.5493 - loss: 0.5928 - precision: 0.8437 - recall: 0.8437\n",
      "Epoch 5/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 179ms/step - accuracy: 0.8123 - auc: 0.8585 - f1_score: 0.5343 - loss: 0.6124 - precision: 0.8123 - recall: 0.8123\n",
      "Epoch 6/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.8395 - auc: 0.8867 - f1_score: 0.5516 - loss: 0.6050 - precision: 0.8395 - recall: 0.8395\n",
      "Epoch 7/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.8336 - auc: 0.8866 - f1_score: 0.5533 - loss: 0.5906 - precision: 0.8336 - recall: 0.8336\n",
      "Epoch 8/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step - accuracy: 0.8641 - auc: 0.9072 - f1_score: 0.5665 - loss: 0.5807 - precision: 0.8641 - recall: 0.8641\n",
      "Epoch 9/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step - accuracy: 0.8380 - auc: 0.8881 - f1_score: 0.5577 - loss: 0.5934 - precision: 0.8380 - recall: 0.8380\n",
      "Epoch 10/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.8526 - auc: 0.9004 - f1_score: 0.5707 - loss: 0.5933 - precision: 0.8526 - recall: 0.8526\n",
      "Epoch 11/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.8808 - auc: 0.9241 - f1_score: 0.5937 - loss: 0.5757 - precision: 0.8808 - recall: 0.8808\n",
      "Epoch 12/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.8565 - auc: 0.9052 - f1_score: 0.5698 - loss: 0.5903 - precision: 0.8565 - recall: 0.8565\n",
      "Epoch 13/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 180ms/step - accuracy: 0.8512 - auc: 0.9044 - f1_score: 0.5762 - loss: 0.5879 - precision: 0.8512 - recall: 0.8512\n",
      "Epoch 14/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.8753 - auc: 0.9223 - f1_score: 0.5874 - loss: 0.5714 - precision: 0.8753 - recall: 0.8753\n",
      "Epoch 15/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.8876 - auc: 0.9297 - f1_score: 0.6030 - loss: 0.5671 - precision: 0.8876 - recall: 0.8876\n",
      "Epoch 16/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.9014 - auc: 0.9422 - f1_score: 0.6074 - loss: 0.5611 - precision: 0.9014 - recall: 0.9014\n",
      "Epoch 17/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 177ms/step - accuracy: 0.8877 - auc: 0.9331 - f1_score: 0.5972 - loss: 0.5696 - precision: 0.8877 - recall: 0.8877\n",
      "Epoch 18/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.8915 - auc: 0.9348 - f1_score: 0.6032 - loss: 0.5728 - precision: 0.8915 - recall: 0.8915\n",
      "Epoch 19/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.9031 - auc: 0.9432 - f1_score: 0.6189 - loss: 0.5574 - precision: 0.9031 - recall: 0.9031\n",
      "Epoch 20/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.9020 - auc: 0.9439 - f1_score: 0.6173 - loss: 0.5566 - precision: 0.9020 - recall: 0.9020\n",
      "Epoch 21/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step - accuracy: 0.8957 - auc: 0.9382 - f1_score: 0.6154 - loss: 0.5484 - precision: 0.8957 - recall: 0.8957\n",
      "Epoch 22/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.8997 - auc: 0.9409 - f1_score: 0.6126 - loss: 0.5615 - precision: 0.8997 - recall: 0.8997\n",
      "Epoch 23/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.8749 - auc: 0.9242 - f1_score: 0.6061 - loss: 0.5842 - precision: 0.8749 - recall: 0.8749\n",
      "Epoch 24/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.9138 - auc: 0.9517 - f1_score: 0.6276 - loss: 0.5533 - precision: 0.9138 - recall: 0.9138\n",
      "Epoch 25/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.9050 - auc: 0.9449 - f1_score: 0.6254 - loss: 0.5568 - precision: 0.9050 - recall: 0.9050\n",
      "Epoch 26/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.8997 - auc: 0.9427 - f1_score: 0.6193 - loss: 0.5579 - precision: 0.8997 - recall: 0.8997\n",
      "Epoch 27/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 179ms/step - accuracy: 0.9088 - auc: 0.9480 - f1_score: 0.6174 - loss: 0.5458 - precision: 0.9088 - recall: 0.9088\n",
      "Epoch 28/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.8995 - auc: 0.9426 - f1_score: 0.6271 - loss: 0.5564 - precision: 0.8995 - recall: 0.8995\n",
      "Epoch 29/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9160 - auc: 0.9538 - f1_score: 0.6424 - loss: 0.5393 - precision: 0.9160 - recall: 0.9160\n",
      "Epoch 30/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step - accuracy: 0.9174 - auc: 0.9538 - f1_score: 0.6362 - loss: 0.5409 - precision: 0.9174 - recall: 0.9174\n",
      "Epoch 31/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.8850 - auc: 0.9345 - f1_score: 0.6082 - loss: 0.5533 - precision: 0.8850 - recall: 0.8850\n",
      "Epoch 32/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.8855 - auc: 0.9344 - f1_score: 0.6099 - loss: 0.5415 - precision: 0.8855 - recall: 0.8855\n",
      "Epoch 33/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.9098 - auc: 0.9509 - f1_score: 0.6383 - loss: 0.5401 - precision: 0.9098 - recall: 0.9098\n",
      "Epoch 34/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 180ms/step - accuracy: 0.9115 - auc: 0.9515 - f1_score: 0.6423 - loss: 0.5348 - precision: 0.9115 - recall: 0.9115\n",
      "Epoch 35/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 182ms/step - accuracy: 0.9147 - auc: 0.9530 - f1_score: 0.6387 - loss: 0.5262 - precision: 0.9147 - recall: 0.9147\n",
      "Epoch 36/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step - accuracy: 0.9122 - auc: 0.9519 - f1_score: 0.6367 - loss: 0.5404 - precision: 0.9122 - recall: 0.9122\n",
      "Epoch 37/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.8918 - auc: 0.9395 - f1_score: 0.6250 - loss: 0.5544 - precision: 0.8918 - recall: 0.8918\n",
      "Epoch 38/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 181ms/step - accuracy: 0.9027 - auc: 0.9455 - f1_score: 0.6351 - loss: 0.5575 - precision: 0.9027 - recall: 0.9027\n",
      "Epoch 39/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 180ms/step - accuracy: 0.9199 - auc: 0.9570 - f1_score: 0.6561 - loss: 0.5419 - precision: 0.9199 - recall: 0.9199\n",
      "Epoch 40/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 178ms/step - accuracy: 0.9222 - auc: 0.9589 - f1_score: 0.6506 - loss: 0.5393 - precision: 0.9222 - recall: 0.9222\n",
      "Epoch 41/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 174ms/step - accuracy: 0.9146 - auc: 0.9552 - f1_score: 0.6475 - loss: 0.5228 - precision: 0.9146 - recall: 0.9146\n",
      "Epoch 42/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 187ms/step - accuracy: 0.9152 - auc: 0.9541 - f1_score: 0.6396 - loss: 0.5237 - precision: 0.9152 - recall: 0.9152\n",
      "Epoch 43/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9186 - auc: 0.9565 - f1_score: 0.6508 - loss: 0.5275 - precision: 0.9186 - recall: 0.9186\n",
      "Epoch 44/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - accuracy: 0.9173 - auc: 0.9561 - f1_score: 0.6443 - loss: 0.5323 - precision: 0.9173 - recall: 0.9173\n",
      "Epoch 45/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9196 - auc: 0.9581 - f1_score: 0.6503 - loss: 0.5355 - precision: 0.9196 - recall: 0.9196\n",
      "Epoch 46/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9162 - auc: 0.9562 - f1_score: 0.6447 - loss: 0.5240 - precision: 0.9162 - recall: 0.9162\n",
      "Epoch 47/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - accuracy: 0.9055 - auc: 0.9497 - f1_score: 0.6368 - loss: 0.5462 - precision: 0.9055 - recall: 0.9055\n",
      "Epoch 48/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 188ms/step - accuracy: 0.9168 - auc: 0.9566 - f1_score: 0.6562 - loss: 0.5372 - precision: 0.9168 - recall: 0.9168\n",
      "Epoch 49/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - accuracy: 0.9124 - auc: 0.9535 - f1_score: 0.6444 - loss: 0.5389 - precision: 0.9124 - recall: 0.9124\n",
      "Epoch 50/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 193ms/step - accuracy: 0.9091 - auc: 0.9491 - f1_score: 0.6409 - loss: 0.5362 - precision: 0.9091 - recall: 0.9091\n",
      "Epoch 51/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - accuracy: 0.9180 - auc: 0.9583 - f1_score: 0.6451 - loss: 0.5173 - precision: 0.9180 - recall: 0.9180\n",
      "Epoch 52/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9135 - auc: 0.9537 - f1_score: 0.6569 - loss: 0.5441 - precision: 0.9135 - recall: 0.9135\n",
      "Epoch 53/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9294 - auc: 0.9641 - f1_score: 0.6646 - loss: 0.5169 - precision: 0.9294 - recall: 0.9294\n",
      "Epoch 54/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9199 - auc: 0.9577 - f1_score: 0.6481 - loss: 0.5201 - precision: 0.9199 - recall: 0.9199\n",
      "Epoch 55/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9245 - auc: 0.9608 - f1_score: 0.6649 - loss: 0.5234 - precision: 0.9245 - recall: 0.9245\n",
      "Epoch 56/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 195ms/step - accuracy: 0.9196 - auc: 0.9598 - f1_score: 0.6602 - loss: 0.5300 - precision: 0.9196 - recall: 0.9196\n",
      "Epoch 57/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 194ms/step - accuracy: 0.9292 - auc: 0.9628 - f1_score: 0.6636 - loss: 0.5249 - precision: 0.9292 - recall: 0.9292\n",
      "Epoch 58/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9198 - auc: 0.9581 - f1_score: 0.6569 - loss: 0.5275 - precision: 0.9198 - recall: 0.9198\n",
      "Epoch 59/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 193ms/step - accuracy: 0.9138 - auc: 0.9546 - f1_score: 0.6569 - loss: 0.5501 - precision: 0.9138 - recall: 0.9138\n",
      "Epoch 60/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9239 - auc: 0.9604 - f1_score: 0.6628 - loss: 0.5243 - precision: 0.9239 - recall: 0.9239\n",
      "Epoch 61/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9226 - auc: 0.9582 - f1_score: 0.6622 - loss: 0.5365 - precision: 0.9226 - recall: 0.9226\n",
      "Epoch 62/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9299 - auc: 0.9638 - f1_score: 0.6735 - loss: 0.5291 - precision: 0.9299 - recall: 0.9299\n",
      "Epoch 63/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - accuracy: 0.9234 - auc: 0.9597 - f1_score: 0.6647 - loss: 0.5268 - precision: 0.9234 - recall: 0.9234\n",
      "Epoch 64/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - accuracy: 0.9264 - auc: 0.9620 - f1_score: 0.6668 - loss: 0.5264 - precision: 0.9264 - recall: 0.9264\n",
      "Epoch 65/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9224 - auc: 0.9602 - f1_score: 0.6677 - loss: 0.5318 - precision: 0.9224 - recall: 0.9224\n",
      "Epoch 66/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 193ms/step - accuracy: 0.9234 - auc: 0.9603 - f1_score: 0.6688 - loss: 0.5304 - precision: 0.9234 - recall: 0.9234\n",
      "Epoch 67/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9185 - auc: 0.9563 - f1_score: 0.6643 - loss: 0.5353 - precision: 0.9185 - recall: 0.9185\n",
      "Epoch 68/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9278 - auc: 0.9622 - f1_score: 0.6804 - loss: 0.5234 - precision: 0.9278 - recall: 0.9278\n",
      "Epoch 69/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - accuracy: 0.9265 - auc: 0.9637 - f1_score: 0.6718 - loss: 0.5216 - precision: 0.9265 - recall: 0.9265\n",
      "Epoch 70/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9272 - auc: 0.9620 - f1_score: 0.6762 - loss: 0.5241 - precision: 0.9272 - recall: 0.9272\n",
      "Epoch 71/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 189ms/step - accuracy: 0.9308 - auc: 0.9640 - f1_score: 0.6694 - loss: 0.5053 - precision: 0.9308 - recall: 0.9308\n",
      "Epoch 72/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9304 - auc: 0.9643 - f1_score: 0.6804 - loss: 0.5124 - precision: 0.9304 - recall: 0.9304\n",
      "Epoch 73/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9349 - auc: 0.9679 - f1_score: 0.6774 - loss: 0.5106 - precision: 0.9349 - recall: 0.9349\n",
      "Epoch 74/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9233 - auc: 0.9611 - f1_score: 0.6692 - loss: 0.5261 - precision: 0.9233 - recall: 0.9233\n",
      "Epoch 75/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9282 - auc: 0.9630 - f1_score: 0.6664 - loss: 0.5188 - precision: 0.9282 - recall: 0.9282\n",
      "Epoch 76/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9365 - auc: 0.9688 - f1_score: 0.6859 - loss: 0.5132 - precision: 0.9365 - recall: 0.9365\n",
      "Epoch 77/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 190ms/step - accuracy: 0.9314 - auc: 0.9653 - f1_score: 0.6656 - loss: 0.5117 - precision: 0.9314 - recall: 0.9314\n",
      "Epoch 78/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9312 - auc: 0.9660 - f1_score: 0.6728 - loss: 0.4980 - precision: 0.9312 - recall: 0.9312\n",
      "Epoch 79/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - accuracy: 0.9301 - auc: 0.9645 - f1_score: 0.6723 - loss: 0.4999 - precision: 0.9301 - recall: 0.9301\n",
      "Epoch 80/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9324 - auc: 0.9664 - f1_score: 0.6685 - loss: 0.5063 - precision: 0.9324 - recall: 0.9324\n",
      "Epoch 81/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9175 - auc: 0.9565 - f1_score: 0.6595 - loss: 0.5106 - precision: 0.9175 - recall: 0.9175\n",
      "Epoch 82/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9241 - auc: 0.9603 - f1_score: 0.6775 - loss: 0.5234 - precision: 0.9241 - recall: 0.9241\n",
      "Epoch 83/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9338 - auc: 0.9677 - f1_score: 0.6765 - loss: 0.5165 - precision: 0.9338 - recall: 0.9338\n",
      "Epoch 84/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9320 - auc: 0.9655 - f1_score: 0.6772 - loss: 0.5035 - precision: 0.9320 - recall: 0.9320\n",
      "Epoch 85/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9349 - auc: 0.9696 - f1_score: 0.6816 - loss: 0.5110 - precision: 0.9349 - recall: 0.9349\n",
      "Epoch 86/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9227 - auc: 0.9612 - f1_score: 0.6721 - loss: 0.5305 - precision: 0.9227 - recall: 0.9227\n",
      "Epoch 87/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9378 - auc: 0.9698 - f1_score: 0.6928 - loss: 0.5158 - precision: 0.9378 - recall: 0.9378\n",
      "Epoch 88/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9256 - auc: 0.9632 - f1_score: 0.6773 - loss: 0.5205 - precision: 0.9256 - recall: 0.9256\n",
      "Epoch 89/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9314 - auc: 0.9670 - f1_score: 0.6749 - loss: 0.5142 - precision: 0.9314 - recall: 0.9314\n",
      "Epoch 90/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.9322 - auc: 0.9678 - f1_score: 0.6805 - loss: 0.5157 - precision: 0.9322 - recall: 0.9322\n",
      "Epoch 91/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9356 - auc: 0.9692 - f1_score: 0.6877 - loss: 0.5087 - precision: 0.9356 - recall: 0.9356\n",
      "Epoch 92/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 192ms/step - accuracy: 0.9280 - auc: 0.9646 - f1_score: 0.6750 - loss: 0.5057 - precision: 0.9280 - recall: 0.9280\n",
      "Epoch 93/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9327 - auc: 0.9682 - f1_score: 0.6790 - loss: 0.5074 - precision: 0.9327 - recall: 0.9327\n",
      "Epoch 94/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9349 - auc: 0.9684 - f1_score: 0.6929 - loss: 0.5124 - precision: 0.9349 - recall: 0.9349\n",
      "Epoch 95/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9284 - auc: 0.9646 - f1_score: 0.6767 - loss: 0.5169 - precision: 0.9284 - recall: 0.9284\n",
      "Epoch 96/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 190ms/step - accuracy: 0.9268 - auc: 0.9632 - f1_score: 0.6761 - loss: 0.5230 - precision: 0.9268 - recall: 0.9268\n",
      "Epoch 97/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9331 - auc: 0.9662 - f1_score: 0.6920 - loss: 0.5189 - precision: 0.9331 - recall: 0.9331\n",
      "Epoch 98/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.9382 - auc: 0.9696 - f1_score: 0.6901 - loss: 0.5028 - precision: 0.9382 - recall: 0.9382\n",
      "Epoch 99/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 172ms/step - accuracy: 0.9312 - auc: 0.9666 - f1_score: 0.6868 - loss: 0.5005 - precision: 0.9312 - recall: 0.9312\n",
      "Epoch 100/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 191ms/step - accuracy: 0.9284 - auc: 0.9637 - f1_score: 0.6814 - loss: 0.5142 - precision: 0.9284 - recall: 0.9284\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9477 - auc: 0.9632 - f1_score: 0.6323 - loss: 0.4507 - precision: 0.9477 - recall: 0.9477\n",
      "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Epoch 1/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 323ms/step - accuracy: 0.5961 - auc: 0.6174 - loss: 0.7083\n",
      "Epoch 2/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 278ms/step - accuracy: 0.7525 - auc: 0.6817 - loss: 0.6249\n",
      "Epoch 3/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 285ms/step - accuracy: 0.7768 - auc: 0.7344 - loss: 0.5843\n",
      "Epoch 4/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 263ms/step - accuracy: 0.7542 - auc: 0.7576 - loss: 0.5852\n",
      "Epoch 5/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 264ms/step - accuracy: 0.7858 - auc: 0.7695 - loss: 0.5618\n",
      "Epoch 6/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 262ms/step - accuracy: 0.8131 - auc: 0.7957 - loss: 0.5393\n",
      "Epoch 7/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 258ms/step - accuracy: 0.7954 - auc: 0.7901 - loss: 0.5358\n",
      "Epoch 8/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 315ms/step - accuracy: 0.8001 - auc: 0.8170 - loss: 0.5190\n",
      "Epoch 9/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 271ms/step - accuracy: 0.8186 - auc: 0.8329 - loss: 0.5040\n",
      "Epoch 10/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 262ms/step - accuracy: 0.8091 - auc: 0.8379 - loss: 0.4947\n",
      "Epoch 11/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 302ms/step - accuracy: 0.8217 - auc: 0.8464 - loss: 0.4782\n",
      "Epoch 12/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 259ms/step - accuracy: 0.8253 - auc: 0.8581 - loss: 0.4777\n",
      "Epoch 13/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 280ms/step - accuracy: 0.8136 - auc: 0.8549 - loss: 0.4749\n",
      "Epoch 14/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 260ms/step - accuracy: 0.8491 - auc: 0.8693 - loss: 0.4419\n",
      "Epoch 15/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 288ms/step - accuracy: 0.8372 - auc: 0.8783 - loss: 0.4362\n",
      "Epoch 16/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 326ms/step - accuracy: 0.8355 - auc: 0.8775 - loss: 0.4525\n",
      "Epoch 17/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 363ms/step - accuracy: 0.8437 - auc: 0.8881 - loss: 0.4292\n",
      "Epoch 18/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 330ms/step - accuracy: 0.8457 - auc: 0.8874 - loss: 0.4237\n",
      "Epoch 19/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 327ms/step - accuracy: 0.8499 - auc: 0.9037 - loss: 0.3993\n",
      "Epoch 20/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 302ms/step - accuracy: 0.8553 - auc: 0.9057 - loss: 0.3942\n",
      "Epoch 21/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 266ms/step - accuracy: 0.8492 - auc: 0.9077 - loss: 0.3978\n",
      "Epoch 22/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 269ms/step - accuracy: 0.8615 - auc: 0.8991 - loss: 0.4004\n",
      "Epoch 23/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 299ms/step - accuracy: 0.8557 - auc: 0.9092 - loss: 0.3824\n",
      "Epoch 24/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 263ms/step - accuracy: 0.8674 - auc: 0.9235 - loss: 0.3635\n",
      "Epoch 25/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 258ms/step - accuracy: 0.8526 - auc: 0.9184 - loss: 0.3680\n",
      "Epoch 26/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 259ms/step - accuracy: 0.8687 - auc: 0.9309 - loss: 0.3494\n",
      "Epoch 27/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 314ms/step - accuracy: 0.8628 - auc: 0.9279 - loss: 0.3495\n",
      "Epoch 28/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 328ms/step - accuracy: 0.8655 - auc: 0.9321 - loss: 0.3393\n",
      "Epoch 29/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 328ms/step - accuracy: 0.8697 - auc: 0.9341 - loss: 0.3370\n",
      "Epoch 30/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 325ms/step - accuracy: 0.8602 - auc: 0.9291 - loss: 0.3495\n",
      "Epoch 31/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 327ms/step - accuracy: 0.8595 - auc: 0.9319 - loss: 0.3335\n",
      "Epoch 32/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 334ms/step - accuracy: 0.8756 - auc: 0.9403 - loss: 0.3187\n",
      "Epoch 33/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 298ms/step - accuracy: 0.8749 - auc: 0.9409 - loss: 0.3150\n",
      "Epoch 34/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 261ms/step - accuracy: 0.8815 - auc: 0.9462 - loss: 0.3019\n",
      "Epoch 35/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 259ms/step - accuracy: 0.8901 - auc: 0.9440 - loss: 0.3024\n",
      "Epoch 36/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 263ms/step - accuracy: 0.8838 - auc: 0.9494 - loss: 0.2963\n",
      "Epoch 37/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 304ms/step - accuracy: 0.8845 - auc: 0.9492 - loss: 0.2930\n",
      "Epoch 38/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 306ms/step - accuracy: 0.8815 - auc: 0.9514 - loss: 0.2862\n",
      "Epoch 39/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 261ms/step - accuracy: 0.8720 - auc: 0.9481 - loss: 0.3016\n",
      "Epoch 40/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 259ms/step - accuracy: 0.8922 - auc: 0.9566 - loss: 0.2694\n",
      "Epoch 41/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 266ms/step - accuracy: 0.8928 - auc: 0.9544 - loss: 0.2731\n",
      "Epoch 42/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 317ms/step - accuracy: 0.8800 - auc: 0.9541 - loss: 0.2857\n",
      "Epoch 43/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 300ms/step - accuracy: 0.8987 - auc: 0.9610 - loss: 0.2606\n",
      "Epoch 44/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 320ms/step - accuracy: 0.8983 - auc: 0.9575 - loss: 0.2659\n",
      "Epoch 45/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 332ms/step - accuracy: 0.9030 - auc: 0.9665 - loss: 0.2386\n",
      "Epoch 46/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.8966 - auc: 0.9617 - loss: 0.2529\n",
      "Epoch 47/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.9030 - auc: 0.9648 - loss: 0.2434\n",
      "Epoch 48/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 331ms/step - accuracy: 0.8981 - auc: 0.9608 - loss: 0.2558\n",
      "Epoch 49/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 298ms/step - accuracy: 0.9065 - auc: 0.9686 - loss: 0.2351\n",
      "Epoch 50/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 321ms/step - accuracy: 0.9018 - auc: 0.9664 - loss: 0.2392\n",
      "Epoch 51/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.9089 - auc: 0.9699 - loss: 0.2240\n",
      "Epoch 52/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 324ms/step - accuracy: 0.9034 - auc: 0.9681 - loss: 0.2325\n",
      "Epoch 53/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 340ms/step - accuracy: 0.9029 - auc: 0.9678 - loss: 0.2343\n",
      "Epoch 54/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.9118 - auc: 0.9700 - loss: 0.2179\n",
      "Epoch 55/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 327ms/step - accuracy: 0.9122 - auc: 0.9712 - loss: 0.2205\n",
      "Epoch 56/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 326ms/step - accuracy: 0.9074 - auc: 0.9700 - loss: 0.2246\n",
      "Epoch 57/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 324ms/step - accuracy: 0.9103 - auc: 0.9690 - loss: 0.2220\n",
      "Epoch 58/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 326ms/step - accuracy: 0.9093 - auc: 0.9723 - loss: 0.2067\n",
      "Epoch 59/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 321ms/step - accuracy: 0.9149 - auc: 0.9754 - loss: 0.2011\n",
      "Epoch 60/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.9037 - auc: 0.9697 - loss: 0.2228\n",
      "Epoch 61/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 324ms/step - accuracy: 0.9201 - auc: 0.9749 - loss: 0.1986\n",
      "Epoch 62/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 326ms/step - accuracy: 0.9151 - auc: 0.9730 - loss: 0.2114\n",
      "Epoch 63/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 324ms/step - accuracy: 0.9117 - auc: 0.9736 - loss: 0.2109\n",
      "Epoch 64/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 326ms/step - accuracy: 0.9202 - auc: 0.9736 - loss: 0.2064\n",
      "Epoch 65/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.9194 - auc: 0.9760 - loss: 0.1992\n",
      "Epoch 66/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 331ms/step - accuracy: 0.9170 - auc: 0.9755 - loss: 0.2014\n",
      "Epoch 67/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.9109 - auc: 0.9725 - loss: 0.2087\n",
      "Epoch 68/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 275ms/step - accuracy: 0.9213 - auc: 0.9787 - loss: 0.1839\n",
      "Epoch 69/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 258ms/step - accuracy: 0.9225 - auc: 0.9773 - loss: 0.1867\n",
      "Epoch 70/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 254ms/step - accuracy: 0.9162 - auc: 0.9782 - loss: 0.1874\n",
      "Epoch 71/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 259ms/step - accuracy: 0.9190 - auc: 0.9755 - loss: 0.1970\n",
      "Epoch 72/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 278ms/step - accuracy: 0.9213 - auc: 0.9774 - loss: 0.1909\n",
      "Epoch 73/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 270ms/step - accuracy: 0.9257 - auc: 0.9793 - loss: 0.1779\n",
      "Epoch 74/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 331ms/step - accuracy: 0.9186 - auc: 0.9747 - loss: 0.2052\n",
      "Epoch 75/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 261ms/step - accuracy: 0.9203 - auc: 0.9758 - loss: 0.1964\n",
      "Epoch 76/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 255ms/step - accuracy: 0.9253 - auc: 0.9786 - loss: 0.1804\n",
      "Epoch 77/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.9250 - auc: 0.9779 - loss: 0.1847\n",
      "Epoch 78/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 259ms/step - accuracy: 0.9197 - auc: 0.9740 - loss: 0.2053\n",
      "Epoch 79/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 251ms/step - accuracy: 0.9198 - auc: 0.9759 - loss: 0.1982\n",
      "Epoch 80/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 316ms/step - accuracy: 0.9175 - auc: 0.9758 - loss: 0.1933\n",
      "Epoch 81/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 353ms/step - accuracy: 0.9312 - auc: 0.9811 - loss: 0.1724\n",
      "Epoch 82/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.9323 - auc: 0.9810 - loss: 0.1694\n",
      "Epoch 83/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 289ms/step - accuracy: 0.9326 - auc: 0.9811 - loss: 0.1714\n",
      "Epoch 84/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 361ms/step - accuracy: 0.9125 - auc: 0.9723 - loss: 0.2141\n",
      "Epoch 85/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 317ms/step - accuracy: 0.9303 - auc: 0.9809 - loss: 0.1729\n",
      "Epoch 86/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 307ms/step - accuracy: 0.9336 - auc: 0.9820 - loss: 0.1626\n",
      "Epoch 87/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 305ms/step - accuracy: 0.9227 - auc: 0.9782 - loss: 0.1841\n",
      "Epoch 88/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 312ms/step - accuracy: 0.9300 - auc: 0.9812 - loss: 0.1667\n",
      "Epoch 89/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 314ms/step - accuracy: 0.9276 - auc: 0.9799 - loss: 0.1744\n",
      "Epoch 90/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 319ms/step - accuracy: 0.9327 - auc: 0.9827 - loss: 0.1627\n",
      "Epoch 91/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.9280 - auc: 0.9798 - loss: 0.1719\n",
      "Epoch 92/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 356ms/step - accuracy: 0.9283 - auc: 0.9792 - loss: 0.1778\n",
      "Epoch 93/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 325ms/step - accuracy: 0.9310 - auc: 0.9809 - loss: 0.1712\n",
      "Epoch 94/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 327ms/step - accuracy: 0.9300 - auc: 0.9820 - loss: 0.1679\n",
      "Epoch 95/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 361ms/step - accuracy: 0.9308 - auc: 0.9821 - loss: 0.1660\n",
      "Epoch 96/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 323ms/step - accuracy: 0.9347 - auc: 0.9833 - loss: 0.1557\n",
      "Epoch 97/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 328ms/step - accuracy: 0.9358 - auc: 0.9830 - loss: 0.1577\n",
      "Epoch 98/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 325ms/step - accuracy: 0.9396 - auc: 0.9843 - loss: 0.1516\n",
      "Epoch 99/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 325ms/step - accuracy: 0.9388 - auc: 0.9844 - loss: 0.1539\n",
      "Epoch 100/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 328ms/step - accuracy: 0.9344 - auc: 0.9819 - loss: 0.1623\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "Epoch 1/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 138ms/step - accuracy: 0.8843 - auc: 0.9093 - f1_score: 0.6366 - loss: 0.3266 - precision: 0.8843 - recall: 0.8843\n",
      "Epoch 2/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9294 - auc: 0.9652 - f1_score: 0.7403 - loss: 0.1631 - precision: 0.9294 - recall: 0.9294\n",
      "Epoch 3/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 140ms/step - accuracy: 0.9376 - auc: 0.9759 - f1_score: 0.7523 - loss: 0.1451 - precision: 0.9376 - recall: 0.9376\n",
      "Epoch 4/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9362 - auc: 0.9826 - f1_score: 0.7513 - loss: 0.1417 - precision: 0.9362 - recall: 0.9362\n",
      "Epoch 5/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9371 - auc: 0.9852 - f1_score: 0.7534 - loss: 0.1353 - precision: 0.9371 - recall: 0.9371\n",
      "Epoch 6/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 141ms/step - accuracy: 0.9362 - auc: 0.9843 - f1_score: 0.7475 - loss: 0.1456 - precision: 0.9362 - recall: 0.9362\n",
      "Epoch 7/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9296 - auc: 0.9834 - f1_score: 0.7395 - loss: 0.1427 - precision: 0.9296 - recall: 0.9296\n",
      "Epoch 8/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 132ms/step - accuracy: 0.9367 - auc: 0.9865 - f1_score: 0.7457 - loss: 0.1342 - precision: 0.9367 - recall: 0.9367\n",
      "Epoch 9/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 140ms/step - accuracy: 0.9339 - auc: 0.9864 - f1_score: 0.7409 - loss: 0.1358 - precision: 0.9339 - recall: 0.9339\n",
      "Epoch 10/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 140ms/step - accuracy: 0.9377 - auc: 0.9863 - f1_score: 0.7522 - loss: 0.1350 - precision: 0.9377 - recall: 0.9377\n",
      "Epoch 11/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9321 - auc: 0.9844 - f1_score: 0.7416 - loss: 0.1403 - precision: 0.9321 - recall: 0.9321\n",
      "Epoch 12/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 140ms/step - accuracy: 0.9352 - auc: 0.9864 - f1_score: 0.7514 - loss: 0.1391 - precision: 0.9352 - recall: 0.9352\n",
      "Epoch 13/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9342 - auc: 0.9868 - f1_score: 0.7505 - loss: 0.1365 - precision: 0.9342 - recall: 0.9342\n",
      "Epoch 14/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9313 - auc: 0.9874 - f1_score: 0.7355 - loss: 0.1359 - precision: 0.9313 - recall: 0.9313\n",
      "Epoch 15/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9361 - auc: 0.9872 - f1_score: 0.7478 - loss: 0.1398 - precision: 0.9361 - recall: 0.9361\n",
      "Epoch 16/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9310 - auc: 0.9858 - f1_score: 0.7370 - loss: 0.1419 - precision: 0.9310 - recall: 0.9310\n",
      "Epoch 17/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9351 - auc: 0.9872 - f1_score: 0.7485 - loss: 0.1345 - precision: 0.9351 - recall: 0.9351\n",
      "Epoch 18/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9359 - auc: 0.9878 - f1_score: 0.7438 - loss: 0.1311 - precision: 0.9359 - recall: 0.9359\n",
      "Epoch 19/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 134ms/step - accuracy: 0.9315 - auc: 0.9874 - f1_score: 0.7443 - loss: 0.1311 - precision: 0.9315 - recall: 0.9315\n",
      "Epoch 20/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 137ms/step - accuracy: 0.9339 - auc: 0.9877 - f1_score: 0.7451 - loss: 0.1288 - precision: 0.9339 - recall: 0.9339\n",
      "Epoch 21/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 140ms/step - accuracy: 0.9318 - auc: 0.9868 - f1_score: 0.7373 - loss: 0.1499 - precision: 0.9318 - recall: 0.9318\n",
      "Epoch 22/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9380 - auc: 0.9876 - f1_score: 0.7533 - loss: 0.1422 - precision: 0.9380 - recall: 0.9380\n",
      "Epoch 23/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 135ms/step - accuracy: 0.9328 - auc: 0.9860 - f1_score: 0.7415 - loss: 0.1329 - precision: 0.9328 - recall: 0.9328\n",
      "Epoch 24/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 136ms/step - accuracy: 0.9391 - auc: 0.9896 - f1_score: 0.7498 - loss: 0.1251 - precision: 0.9391 - recall: 0.9391\n",
      "Epoch 25/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9380 - auc: 0.9884 - f1_score: 0.7553 - loss: 0.1289 - precision: 0.9380 - recall: 0.9380\n",
      "Epoch 26/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 137ms/step - accuracy: 0.9349 - auc: 0.9882 - f1_score: 0.7475 - loss: 0.1340 - precision: 0.9349 - recall: 0.9349\n",
      "Epoch 27/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 113ms/step - accuracy: 0.9387 - auc: 0.9878 - f1_score: 0.7562 - loss: 0.1323 - precision: 0.9387 - recall: 0.9387\n",
      "Epoch 28/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9330 - auc: 0.9878 - f1_score: 0.7468 - loss: 0.1382 - precision: 0.9330 - recall: 0.9330\n",
      "Epoch 29/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 140ms/step - accuracy: 0.9328 - auc: 0.9878 - f1_score: 0.7414 - loss: 0.1301 - precision: 0.9328 - recall: 0.9328\n",
      "Epoch 30/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9313 - auc: 0.9874 - f1_score: 0.7465 - loss: 0.1422 - precision: 0.9313 - recall: 0.9313\n",
      "Epoch 31/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9329 - auc: 0.9882 - f1_score: 0.7426 - loss: 0.1306 - precision: 0.9329 - recall: 0.9329\n",
      "Epoch 32/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9341 - auc: 0.9888 - f1_score: 0.7423 - loss: 0.1245 - precision: 0.9341 - recall: 0.9341\n",
      "Epoch 33/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 136ms/step - accuracy: 0.9358 - auc: 0.9877 - f1_score: 0.7487 - loss: 0.1530 - precision: 0.9358 - recall: 0.9358\n",
      "Epoch 34/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 140ms/step - accuracy: 0.9371 - auc: 0.9884 - f1_score: 0.7509 - loss: 0.1305 - precision: 0.9371 - recall: 0.9371\n",
      "Epoch 35/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9318 - auc: 0.9867 - f1_score: 0.7415 - loss: 0.1378 - precision: 0.9318 - recall: 0.9318\n",
      "Epoch 36/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 137ms/step - accuracy: 0.9322 - auc: 0.9877 - f1_score: 0.7330 - loss: 0.1373 - precision: 0.9322 - recall: 0.9322\n",
      "Epoch 37/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9330 - auc: 0.9871 - f1_score: 0.7366 - loss: 0.1371 - precision: 0.9330 - recall: 0.9330\n",
      "Epoch 38/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9390 - auc: 0.9879 - f1_score: 0.7544 - loss: 0.1284 - precision: 0.9390 - recall: 0.9390\n",
      "Epoch 39/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 137ms/step - accuracy: 0.9361 - auc: 0.9890 - f1_score: 0.7530 - loss: 0.1292 - precision: 0.9361 - recall: 0.9361\n",
      "Epoch 40/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9318 - auc: 0.9868 - f1_score: 0.7449 - loss: 0.1396 - precision: 0.9318 - recall: 0.9318\n",
      "Epoch 41/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 136ms/step - accuracy: 0.9400 - auc: 0.9890 - f1_score: 0.7519 - loss: 0.1263 - precision: 0.9400 - recall: 0.9400\n",
      "Epoch 42/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 131ms/step - accuracy: 0.9336 - auc: 0.9870 - f1_score: 0.7477 - loss: 0.1332 - precision: 0.9336 - recall: 0.9336\n",
      "Epoch 43/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.9361 - auc: 0.9880 - f1_score: 0.7486 - loss: 0.1340 - precision: 0.9361 - recall: 0.9361\n",
      "Epoch 44/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - accuracy: 0.9417 - auc: 0.9894 - f1_score: 0.7617 - loss: 0.1292 - precision: 0.9417 - recall: 0.9417\n",
      "Epoch 45/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 136ms/step - accuracy: 0.9370 - auc: 0.9874 - f1_score: 0.7496 - loss: 0.1309 - precision: 0.9370 - recall: 0.9370\n",
      "Epoch 46/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 137ms/step - accuracy: 0.9442 - auc: 0.9887 - f1_score: 0.7722 - loss: 0.1307 - precision: 0.9442 - recall: 0.9442\n",
      "Epoch 47/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9389 - auc: 0.9880 - f1_score: 0.7483 - loss: 0.1316 - precision: 0.9389 - recall: 0.9389\n",
      "Epoch 48/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9309 - auc: 0.9873 - f1_score: 0.7326 - loss: 0.1345 - precision: 0.9309 - recall: 0.9309\n",
      "Epoch 49/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9359 - auc: 0.9875 - f1_score: 0.7504 - loss: 0.1290 - precision: 0.9359 - recall: 0.9359\n",
      "Epoch 50/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9408 - auc: 0.9888 - f1_score: 0.7570 - loss: 0.1265 - precision: 0.9408 - recall: 0.9408\n",
      "Epoch 51/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9420 - auc: 0.9881 - f1_score: 0.7630 - loss: 0.1266 - precision: 0.9420 - recall: 0.9420\n",
      "Epoch 52/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9368 - auc: 0.9858 - f1_score: 0.7491 - loss: 0.1372 - precision: 0.9368 - recall: 0.9368\n",
      "Epoch 53/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9449 - auc: 0.9888 - f1_score: 0.7760 - loss: 0.1259 - precision: 0.9449 - recall: 0.9449\n",
      "Epoch 54/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9398 - auc: 0.9876 - f1_score: 0.7597 - loss: 0.1370 - precision: 0.9398 - recall: 0.9398\n",
      "Epoch 55/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9395 - auc: 0.9881 - f1_score: 0.7577 - loss: 0.1189 - precision: 0.9395 - recall: 0.9395\n",
      "Epoch 56/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 134ms/step - accuracy: 0.9353 - auc: 0.9876 - f1_score: 0.7449 - loss: 0.1276 - precision: 0.9353 - recall: 0.9353\n",
      "Epoch 57/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 137ms/step - accuracy: 0.9345 - auc: 0.9869 - f1_score: 0.7494 - loss: 0.1423 - precision: 0.9345 - recall: 0.9345\n",
      "Epoch 58/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 139ms/step - accuracy: 0.9371 - auc: 0.9889 - f1_score: 0.7490 - loss: 0.1286 - precision: 0.9371 - recall: 0.9371\n",
      "Epoch 59/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 136ms/step - accuracy: 0.9337 - auc: 0.9876 - f1_score: 0.7384 - loss: 0.1385 - precision: 0.9337 - recall: 0.9337\n",
      "Epoch 60/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 140ms/step - accuracy: 0.9398 - auc: 0.9883 - f1_score: 0.7568 - loss: 0.1284 - precision: 0.9398 - recall: 0.9398\n",
      "Epoch 61/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9396 - auc: 0.9889 - f1_score: 0.7559 - loss: 0.1261 - precision: 0.9396 - recall: 0.9396\n",
      "Epoch 62/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.9372 - auc: 0.9880 - f1_score: 0.7571 - loss: 0.1320 - precision: 0.9372 - recall: 0.9372\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9558 - auc: 0.9951 - f1_score: 0.7856 - loss: 0.1030 - precision: 0.9558 - recall: 0.9558\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9368 - auc: 0.9755 - f1_score: 0.6017 - loss: 0.2490 - precision: 0.9368 - recall: 0.9368\n",
      "\n",
      "=== Phase 1: Test Evaluation Results ===\n",
      "  loss  accuracy  precision  recall    auc  f1_score\n",
      "0.4476    0.9486     0.9486  0.9486 0.9685    0.6735\n",
      "\n",
      "=== Phase 3: Train Evaluation Results ===\n",
      "  loss  accuracy  precision  recall    auc  f1_score\n",
      "0.0993    0.9588     0.9588  0.9588 0.9955    0.8112\n",
      "\n",
      "=== Phase 3: Test Evaluation Results ===\n",
      "  loss  accuracy  precision  recall    auc  f1_score\n",
      "0.2369    0.9381     0.9381  0.9381 0.9772    0.6291\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "XD_np = np.array(XD)\n",
    "labels_np = np.array(labels)\n",
    "\n",
    "# Remove samples that don't have labels\n",
    "index = ~np.isnan(labels_np)\n",
    "labels_np = labels_np[index]\n",
    "XD_np = XD_np[index]\n",
    "\n",
    "# Filter the corresponding SMILES\n",
    "filtered_smiles = smiles.iloc[index].values\n",
    "\n",
    "# Create a Dataset using SMILES as identifiers\n",
    "dataset = NumpyDataset(X=XD_np, y=labels_np, ids=filtered_smiles)\n",
    "\n",
    "# Create a ScaffoldSplitter\n",
    "splitter = ScaffoldSplitter()\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(\n",
    "    dataset, frac_train=0.8, frac_valid=0.1, frac_test=0.1\n",
    ")\n",
    "\n",
    "# Extract training and test indices\n",
    "train_indices = train_dataset.ids\n",
    "test_indices = test_dataset.ids\n",
    "smiles_to_index = {smile: idx for idx, smile in enumerate(filtered_smiles)}\n",
    "\n",
    "# Convert SMILES to indices\n",
    "train_indices = np.array([smiles_to_index[smile] for smile in train_indices])\n",
    "test_indices = np.array([smiles_to_index[smile] for smile in test_indices])\n",
    "\n",
    "# Split the data based on the indices\n",
    "X_train, X_test = XD_np[train_indices], XD_np[test_indices]\n",
    "y_train, y_test = labels_np[train_indices], labels_np[test_indices]\n",
    "\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Number of test samples: {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train_cat = to_categorical(y_train, num_classes=2)\n",
    "y_test_cat = to_categorical(y_test, num_classes=2)\n",
    "# Compute class weights to handle class imbalance\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train.ravel()\n",
    ")\n",
    "class_weight = {\n",
    "    0: class_weights_array[0],\n",
    "    1: class_weights_array[1]\n",
    "}\n",
    "\n",
    "# === Define Optimizer for Interaction Model ===\n",
    "opt = optimizers.Adam(learning_rate=0.0001)\n",
    "interactionModel.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=METRICS_CATEGORICAL)\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=30, verbose=1, mode='min', restore_best_weights=True)\n",
    "reduce_lr = LearningRateScheduler(lambda epoch: 1e-3 * 0.9 ** epoch)\n",
    "\n",
    "# === Phase 1: Train Interaction Model ===\n",
    "interactionModel.fit(\n",
    "    X_train, y_train_cat,\n",
    "    batch_size=256, epochs=100, class_weight=class_weight,\n",
    "    callbacks=[early_stopping], verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate Phase 1 on test data\n",
    "test_eval_phase1 = interactionModel.evaluate(X_test, y_test_cat, verbose=1)\n",
    "\n",
    "# === Feature Extraction ===\n",
    "feature_train = model_feature.predict(X_train)\n",
    "feature_test = model_feature.predict(X_test)\n",
    "\n",
    "# === Phase 2: Train Model Phase 2 ===\n",
    "opt_phaz2 = optimizers.Adam(learning_rate=0.001)\n",
    "model_phaz2.compile(optimizer=opt_phaz2, loss=\"binary_crossentropy\", metrics=METRICS_BINARY)\n",
    "model_phaz2.fit(\n",
    "    feature_train, y_train,\n",
    "    batch_size=256, epochs=100,class_weight=class_weight,\n",
    "    callbacks=[early_stopping], verbose=1\n",
    ")\n",
    "\n",
    "# === Freeze Transformer Blocks ===\n",
    "new_transformer_block.set_weights(transformer_block1.get_weights())\n",
    "new_transformer_block2.set_weights(transformer_block2.get_weights())\n",
    "\n",
    "# === Phase 3: Train Model Phase 3 ===\n",
    "opt_phaz3 = optimizers.Adam(learning_rate=0.0001)\n",
    "model_phaz3.compile(optimizer=opt_phaz3, loss=\"categorical_crossentropy\", metrics=METRICS_CATEGORICAL)\n",
    "\n",
    "model_phaz3.fit(\n",
    "    X_train, y_train_cat,\n",
    "    batch_size=256, epochs=100,class_weight=class_weight,\n",
    "    callbacks=[early_stopping], verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate Phase 3 on both training and testing data\n",
    "train_eval_phase3 = model_phaz3.evaluate(X_train, y_train_cat, verbose=1)\n",
    "test_eval_phase3 = model_phaz3.evaluate(X_test, y_test_cat, verbose=1)\n",
    "\n",
    "# === Function to Format Results ===\n",
    "def format_results(phase1_result, phase3_train_result, phase3_test_result):\n",
    "    # Define Metric Names\n",
    "    phase1_metrics = ['loss', 'accuracy', 'precision', 'recall', 'auc', 'f1_score']\n",
    "    phase3_metrics = ['loss', 'accuracy', 'precision', 'recall', 'auc', 'f1_score']\n",
    "\n",
    "    # Create DataFrames\n",
    "    phase1_test_df = pd.DataFrame([phase1_result], columns=phase1_metrics)\n",
    "    phase3_train_df = pd.DataFrame([phase3_train_result], columns=phase3_metrics)\n",
    "    phase3_test_df = pd.DataFrame([test_eval_phase3], columns=phase3_metrics)\n",
    "\n",
    "    # Display the Results\n",
    "    print(\"\\n=== Phase 1: Test Evaluation Results ===\")\n",
    "    print(phase1_test_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    print(\"\\n=== Phase 3: Train Evaluation Results ===\")\n",
    "    print(phase3_train_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    print(\"\\n=== Phase 3: Test Evaluation Results ===\")\n",
    "    print(phase3_test_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "\n",
    "# === Display Results ===\n",
    "format_results(test_eval_phase1, train_eval_phase3, test_eval_phase3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1f92c30c"
   },
   "source": [
    "## Performance Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6a64840e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 48/129\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 18ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      3976\n",
      "           1       0.23      0.40      0.29       130\n",
      "\n",
      "    accuracy                           0.94      4106\n",
      "   macro avg       0.60      0.68      0.63      4106\n",
      "weighted avg       0.96      0.94      0.95      4106\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhdxJREFUeJzt3XdYU9cfBvA3jLCH7Km4V50o1r1otVpHqwJOnK1WrdW6t1al1rpnnbgVZ7V1VK22at2IeyviAkVkj0Byfn/wMzUFlLAuhPfzPDwmN3e8uQL5cu6558iEEAJEREREOkJP6gBEREREeYnFDREREekUFjdERESkU1jcEBERkU5hcUNEREQ6hcUNERER6RQWN0RERKRTWNwQERGRTmFxQ0RERDqFxQ1RHvHw8EDv3r2ljlHsNGvWDM2aNZM6xgdNnToVMpkMkZGRUkcpdGQyGaZOnZon+woNDYVMJkNgYGCe7I+KJhY3VCQEBgZCJpOpvwwMDODq6orevXvj2bNnUscr1BISEvDDDz+gevXqMDU1hZWVFRo3bowNGzagqMy+cvPmTUydOhWhoaFSR8lAqVRi3bp1aNasGWxsbGBkZAQPDw/06dMHFy9elDpentiyZQsWLFggdQwNhTETFR4GUgcg0sb06dNRunRpJCcn4+zZswgMDMSpU6dw/fp1GBsbS5rtzp070NMrXH8vREREoGXLlrh16xb8/PwwZMgQJCcnY9euXfD398eBAwewefNm6OvrSx31vW7evIlp06ahWbNm8PDw0Hjtjz/+kCYUgKSkJHz55Zc4dOgQmjRpgvHjx8PGxgahoaEICgrC+vXrERYWBjc3N8ky5oUtW7bg+vXr+O677/Jl/0lJSTAw0O7jKKtMpUqVQlJSEgwNDfMwIRU1LG6oSPnss89Qp04dAED//v1hZ2eH2bNnY9++ffDx8ZE0m5GRUYEfMzk5GXK5PMuiyt/fH7du3cKePXvQvn179fJvv/0Wo0aNws8//4xatWphzJgxBRUZQHprkpmZWZ7sSy6X58l+cmLUqFE4dOgQ5s+fn+FDdsqUKZg/f36B5hFCIDk5GSYmJgV63JxQqVRQKBQwNjbO0z9MZDKZ5H/oUCEgiIqAdevWCQDiwoULGst/++03AUDMmjVLY/mtW7dEp06dRIkSJYSRkZHw9PQUv/76a4b9vnnzRnz33XeiVKlSQi6XC1dXV9GzZ0/x6tUr9TrJycli8uTJomzZskIulws3NzcxatQokZycrLGvUqVKCX9/fyGEEBcuXBAARGBgYIZjHjp0SAAQ+/fvVy97+vSp6NOnj3BwcBByuVxUqVJFrFmzRmO748ePCwBi69atYsKECcLFxUXIZDLx5s2bTM/ZmTNnBADRt2/fTF9PTU0V5cuXFyVKlBCJiYlCCCEePXokAIg5c+aIefPmiZIlSwpjY2PRpEkTce3atQz7yM55fvt/d+LECTFo0CBhb28vrK2thRBChIaGikGDBokKFSoIY2NjYWNjIzp37iwePXqUYfv/fh0/flwIIUTTpk1F06ZNM5yn7du3ixkzZghXV1dhZGQkWrRoIe7du5fhPSxZskSULl1aGBsbi7p164q///47wz4z8+TJE2FgYCA++eST96731pQpUwQAce/ePeHv7y+srKyEpaWl6N27t0hISNBYd+3ataJ58+bC3t5eyOVyUblyZbFs2bIM+yxVqpRo27atOHTokPD09BRGRkZi/vz5Wu1DCCEOHDggmjRpIszNzYWFhYWoU6eO2Lx5sxAi/fz+99yXKlVKvW12fz4AiMGDB4tNmzaJKlWqCAMDA7Fnzx71a1OmTFGvGxsbK4YNG6b+ubS3txfe3t7i0qVLH8z09nt43bp1Gse/deuW6NKli7CzsxPGxsaiQoUKYvz48e/7L6MijC03VKS97YNRokQJ9bIbN26gYcOGcHV1xdixY2FmZoagoCB07NgRu3btwhdffAEAiI+PR+PGjXHr1i307dsXtWvXRmRkJPbt24enT5/Czs4OKpUK7du3x6lTp/DVV1+hcuXKuHbtGubPn4+7d+9i7969meaqU6cOypQpg6CgIPj7+2u8tn37dpQoUQKtWrUCkH7p6OOPP4ZMJsOQIUNgb2+PgwcPol+/foiNjc3QIvDDDz9ALpdj5MiRSElJybLlYv/+/QCAXr16Zfq6gYEBunXrhmnTpuH06dPw9vZWv7ZhwwbExcVh8ODBSE5OxsKFC9GiRQtcu3YNjo6OWp3nt7755hvY29tj8uTJSEhIAABcuHAB//zzD/z8/ODm5obQ0FAsX74czZo1w82bN2FqaoomTZrg22+/xaJFizB+/HhUrlwZANT/ZuXHH3+Enp4eRo4ciZiYGPz000/o3r07zp07p15n+fLlGDJkCBo3bozhw4cjNDQUHTt2RIkSJT54KengwYNIS0tDz54937vef/n4+KB06dIICAhAcHAwVq9eDQcHB8yePVsjV9WqVdG+fXsYGBhg//79+Oabb6BSqTB48GCN/d25cwddu3bF119/jQEDBqBixYpa7SMwMBB9+/ZF1apVMW7cOFhbW+Py5cs4dOgQunXrhgkTJiAmJgZPnz5Vt0SZm5sDgNY/H3/++SeCgoIwZMgQ2NnZZbjE+NbAgQOxc+dODBkyBFWqVMHr169x6tQp3Lp1C7Vr135vpsxcvXoVjRs3hqGhIb766it4eHjgwYMH2L9/P2bOnJm9/zgqWqSuroiy4+1f70ePHhWvXr0ST548ETt37hT29vbCyMhIPHnyRL1uy5YtRbVq1TT+clSpVKJBgwaifPny6mWTJ08WAMTu3bszHE+lUgkhhNi4caPQ09MTJ0+e1Hh9xYoVAoA4ffq0etm7LTdCCDFu3DhhaGgooqKi1MtSUlKEtbW1RmtKv379hLOzs4iMjNQ4hp+fn7CyslK3qrxtkShTpox62ft07NhRAMiyZUcIIXbv3i0AiEWLFgkh/v2r18TERDx9+lS93rlz5wQAMXz4cPWy7J7nt/93jRo1EmlpaRrHz+x9vG1x2rBhg3rZjh07NFpr3pVVy03lypVFSkqKevnChQsFAHULVEpKirC1tRV169YVqamp6vUCAwMFgA+23AwfPlwAEJcvX37vem+9bbn5b0vaF198IWxtbTWWZXZeWrVqJcqUKaOxrFSpUgKAOHToUIb1s7OP6OhoYWFhIerVqyeSkpI01n37MyCEEG3bttVorXlLm58PAEJPT0/cuHEjw37wn5YbKysrMXjw4AzrvSurTJm13DRp0kRYWFiIx48fZ/keSbcUrt6PRB/g7e0Ne3t7uLu7o3PnzjAzM8O+ffvUf2VHRUXhzz//hI+PD+Li4hAZGYnIyEi8fv0arVq1wr1799R3V+3atQs1atTI0MIApF+3B4AdO3agcuXKqFSpknpfkZGRaNGiBQDg+PHjWWb19fVFamoqdu/erV72xx9/IDo6Gr6+vgDS+0js2rUL7dq1gxBC4xitWrVCTEwMgoODNfbr7++frT4VcXFxAAALC4ss13n7WmxsrMbyjh07wtXVVf3cy8sL9erVw4EDBwBod57fGjBgQIaOy+++j9TUVLx+/RrlypWDtbV1hvetrT59+mi0ajVu3BgA8PDhQwDAxYsX8fr1awwYMECjM2v37t01WgKz8vacve/8ZmbgwIEazxs3bozXr19r/B+8e15iYmIQGRmJpk2b4uHDh4iJidHYvnTp0upWwHdlZx9HjhxBXFwcxo4dm6GfytufgffR9uejadOmqFKlygf3a21tjXPnzuH58+cfXPdDXr16hb///ht9+/ZFyZIlNV7LznukoomXpahIWbp0KSpUqICYmBisXbsWf//9t0ZH3vv370MIgUmTJmHSpEmZ7uPly5dwdXXFgwcP0KlTp/ce7969e7h16xbs7e2z3FdWatSogUqVKmH79u3o168fgPRLUnZ2dupf/q9evUJ0dDRWrlyJlStXZusYpUuXfm/mt95+6MbFxcHa2jrTdbIqgMqXL59h3QoVKiAoKAiAduf5fbmTkpIQEBCAdevW4dmzZxq3pv/3Q1xb//0ge1uwvHnzBgDw+PFjAEC5cuU01jMwMMjycsm7LC0tAfx7DvMi19t9nj59GlOmTMGZM2eQmJiosX5MTAysrKzUz7P6fsjOPh48eAAA+Oijj7R6D29p+/OR3e/dn376Cf7+/nB3d4enpyfatGmDXr16oUyZMlpnfFvM5vQ9UtHE4oaKFC8vL/XdUh07dkSjRo3QrVs33LlzB+bm5lCpVACAkSNHZvrXLJDxw+x9VCoVqlWrhnnz5mX6uru7+3u39/X1xcyZMxEZGQkLCwvs27cPXbt2VbcUvM3bo0ePDH1z3qpevbrG8+zeCVO5cmXs3bsXV69eRZMmTTJd5+rVqwCQrb+m35WT85xZ7qFDh2LdunX47rvvUL9+fVhZWUEmk8HPz099jJzK6vZ2kUdj+1SqVAkAcO3aNdSsWTPb230o14MHD9CyZUtUqlQJ8+bNg7u7O+RyOQ4cOID58+dnOC+ZnVdt95FT2v58ZPd718fHB40bN8aePXvwxx9/YM6cOZg9ezZ2796Nzz77LNe5SfexuKEiS19fHwEBAWjevDmWLFmCsWPHqv+yMzQ01Oggm5myZcvi+vXrH1znypUraNmyZY6asH19fTFt2jTs2rULjo6OiI2NhZ+fn/p1e3t7WFhYQKlUfjCvtj7//HMEBARgw4YNmRY3SqUSW7ZsQYkSJdCwYUON1+7du5dh/bt376pbNLQ5z++zc+dO+Pv7Y+7cueplycnJiI6O1lgvPy4flCpVCkB6K1Tz5s3Vy9PS0hAaGpqhqPyvzz77DPr6+ti0aZPWnYrfZ//+/UhJScG+ffs0Wnnedwk0p/soW7YsAOD69evvLfqzOv+5/fl4H2dnZ3zzzTf45ptv8PLlS9SuXRszZ85UFzfZPd7b79UP/ayTbmGfGyrSmjVrBi8vLyxYsADJyclwcHBAs2bN8Msvv+DFixcZ1n/16pX6cadOnXDlyhXs2bMnw3pv/4r28fHBs2fPsGrVqgzrJCUlqe/6yUrlypVRrVo1bN++Hdu3b4ezs7NGoaGvr49OnTph165dmf7yfTevtho0aABvb2+sW7cOv/32W4bXJ0yYgLt372L06NEZ/qLeu3evRp+Z8+fP49y5c+oPFm3O8/vo6+tnaElZvHgxlEqlxrK3Y+L8t+jJjTp16sDW1harVq1CWlqaevnmzZvVl67ex93dHQMGDMAff/yBxYsXZ3hdpVJh7ty5ePr0qVa53rbs/PcS3bp16/J8H59++iksLCwQEBCA5ORkjdfe3dbMzCzTy4S5/fnIjFKpzHAsBwcHuLi4ICUl5YOZ/sve3h5NmjTB2rVrERYWpvFaXrXiUeHDlhsq8kaNGoUuXbogMDAQAwcOxNKlS9GoUSNUq1YNAwYMQJkyZRAREYEzZ87g6dOnuHLlinq7nTt3okuXLujbty88PT0RFRWFffv2YcWKFahRowZ69uyJoKAgDBw4EMePH0fDhg2hVCpx+/ZtBAUF4fDhw+rLZFnx9fXF5MmTYWxsjH79+mUYcO/HH3/E8ePHUa9ePQwYMABVqlRBVFQUgoODcfToUURFReX43GzYsAEtW7ZEhw4d0K1bNzRu3BgpKSnYvXs3Tpw4AV9fX4waNSrDduXKlUOjRo0waNAgpKSkYMGCBbC1tcXo0aPV62T3PL/P559/jo0bN8LKygpVqlTBmTNncPToUdja2mqsV7NmTejr62P27NmIiYmBkZERWrRoAQcHhxyfG7lcjqlTp2Lo0KFo0aIFfHx8EBoaisDAQJQtWzZbLQNz587FgwcP8O2332L37t34/PPPUaJECYSFhWHHjh24ffu2Rktddnz66aeQy+Vo164dvv76a8THx2PVqlVwcHDItJDMzT4sLS0xf/589O/fH3Xr1kW3bt1QokQJXLlyBYmJiVi/fj0AwNPTE9u3b8eIESNQt25dmJubo127dnny8/FfcXFxcHNzQ+fOnVGjRg2Ym5vj6NGjuHDhgkYLX1aZMrNo0SI0atQItWvXxldffYXSpUsjNDQUv//+O0JCQrTKR0WEJPdoEWkpq0H8hBBCqVSKsmXLirJly6pvNX7w4IHo1auXcHJyEoaGhsLV1VV8/vnnYufOnRrbvn79WgwZMkS4urqqByDz9/fXuC1boVCI2bNni6pVqwojIyNRokQJ4enpKaZNmyZiYmLU6/33VvC37t27px5o7NSpU5m+v4iICDF48GDh7u4uDA0NhZOTk2jZsqVYuXKlep23tzjv2LFDq3MXFxcnpk6dKqpWrSpMTEyEhYWFaNiwoQgMDMxwK+y7g/jNnTtXuLu7CyMjI9G4cWNx5cqVDPvOznl+3//dmzdvRJ8+fYSdnZ0wNzcXrVq1Erdv3870XK5atUqUKVNG6OvrZ2sQv/+ep6wGd1u0aJEoVaqUMDIyEl5eXuL06dPC09NTtG7dOhtnV4i0tDSxevVq0bhxY2FlZSUMDQ1FqVKlRJ8+fTRuE397K/i7A0S+e37eHbhw3759onr16sLY2Fh4eHiI2bNni7Vr12ZY7+0gfpnJ7j7ertugQQNhYmIiLC0thZeXl9i6dav69fj4eNGtWzdhbW2dYRC/7P584P+D+GUG79wKnpKSIkaNGiVq1KghLCwshJmZmahRo0aGAQizypTV//P169fFF198IaytrYWxsbGoWLGimDRpUqZ5qOiTCcF2OSJKFxoaitKlS2POnDkYOXKk1HEkoVKpYG9vjy+//DLTyy1EVPixzw0RFVvJyckZ+l1s2LABUVFRaNasmTShiCjX2OeGiIqts2fPYvjw4ejSpQtsbW0RHByMNWvW4KOPPkKXLl2kjkdEOcTihoiKLQ8PD7i7u2PRokWIioqCjY0NevXqhR9//FHS2caJKHfY54aIiIh0CvvcEBERkU5hcUNEREQ6pdj1uVGpVHj+/DksLCw4IywREVERIYRAXFwcXFxcMgyG+l/Frrh5/vz5Byc7JCIiosLpyZMncHNze+86xa64sbCwAJB+ciwtLSVOQ0RERNkRGxsLd3d39ef4+xS74ubtpShLS0sWN0REREVMdrqUsEMxERER6RQWN0RERKRTWNwQERGRTmFxQ0RERDqFxQ0RERHpFBY3REREpFNY3BAREZFOYXFDREREOoXFDREREekUFjdERESkUyQtbv7++2+0a9cOLi4ukMlk2Lt37we3OXHiBGrXrg0jIyOUK1cOgYGB+Z6TiIiIig5Ji5uEhATUqFEDS5cuzdb6jx49Qtu2bdG8eXOEhITgu+++Q//+/XH48OF8TkpERERFhaQTZ3722Wf47LPPsr3+ihUrULp0acydOxcAULlyZZw6dQrz589Hq1at8ismERERZUEIgRcxyVAJoV4mN9CDg4WxZJmK1KzgZ86cgbe3t8ayVq1a4bvvvstym5SUFKSkpKifx8bG5lc8IiKiYmf0zqvYcempxrLaJa2x+5uGEiUqYh2Kw8PD4ejoqLHM0dERsbGxSEpKynSbgIAAWFlZqb/c3d0LIioREVGxcPVpDJSJMZAlx8DIQA9GBnow1Je2vChSLTc5MW7cOIwYMUL9PDY2lgUOERGRls48eI0Td19mWP7w2gW82DELtap/hLN//wl9fX0J0mkqUsWNk5MTIiIiNJZFRETA0tISJiYmmW5jZGQEIyOjgohHRESks4Ztu4yXcf928xBChdgzOxB9ajMgVHj9MhwvX76Es7OzhCnTFanLUvXr18exY8c0lh05cgT169eXKBEREVHxkJCSBgDwreOOrh9ZwPDIj4g+uREQKjT87EtcCb5YKAobQOLiJj4+HiEhIQgJCQGQfqt3SEgIwsLCAKRfUurVq5d6/YEDB+Lhw4cYPXo0bt++jWXLliEoKAjDhw+XIj4REVGxEJWgQIJCCQCoqf8UgaN88eDyPzA1NUVgYCBOHdgFCwsLiVP+S9LLUhcvXkTz5s3Vz9/2jfH390dgYCBevHihLnQAoHTp0vj9998xfPhwLFy4EG5ubli9ejVvAyciIspHV55EAwCESonp48ciPDwcVatWRVBQEKpUqSJtuEzIhHjnxvRiIDY2FlZWVoiJiYGlpaXUcYiIiAqt689icCc8DrdexGL1qUeo4GiOOS2ssWLFCsydOxempqYFlkWbz+8i1aGYiIiICkZMUiq+XPYPYu5fRFrMS1jUbA1zIwPUqFEDy5cvlzree7G4ISIiogyi4pIQcTwQsWd2QE9fHw0/rouhLepKHStbWNwQEREVUX/dfYUlf95DqjJve5gkvXmJC+umIvbhVQDAVwP6Y/5YHxgbSzelgjZY3BARERVR6/8JxYXQN3m6z6QHFxD5+3yokmIhk5ugis8oLF8+LU+Pkd9Y3BARERURSpXAnfA49SSV0YkKAECfhh5oWNYu1/tfuzAAW3cuBACUr1IdE+euRJtGNXO934LG4oaIiKiI+D4oBHtDnmdY/pGLFbyrOGayhXauVHDHVgBDhw7FnDlziuwI/yxuiIiIiogHrxIAACVMDWFsmD6Hk525ERqUs83xPhMSEmBmZgYgfby5evXqoVGjRrkPKyEWN0RERBJISEnDkuP38To+5cMr/9/TN4kAgHk+NdG8kkOujq9QKDB69GgcPnwYFy5cgLm5OWQyWZEvbAAWN0RERJI4eisCy088yNG2liaGuTr2w4cP4evri4sXLwIA9u/fj65du+Zqn4UJixsiIiIJpKSqAABl7M3QqbZbtrdztTZB7ZLWOT7url270LdvX8TGxqJEiRJYv3492rVrl+P9FUYsboiIiCSw49ITAEBpWzMMbl4u34+XnJyMkSNHYunSpQCABg0aYOvWrShZsmS+H7ugSTorOBERUXH1tkNwcpqyQI43atQodWEzZswYnDhxQicLG4AtN0RERJlSqQQOXH+B8JjkfNn/szdJAIDOntm/JJUbEyZMwIkTJzBnzhy0bt26QI4pFRY3REREmbgQGoUhWy7n+3GMDPTzZb9JSUnYs2cPunXrBgBwcnLClStXoKen+xdtWNwQERFlIjopFQBgYyZHk/K5H/03M/YWRmhW0T7P93v79m34+Pjg2rVrMDAwgI+PDwAUi8IGYHFDRETFlEolMHTrZVx/HpPp6wkp6X1hStuZYYFfrYKMlisbNmzAoEGDkJiYCAcHB9jY2EgdqcCxuCEiomLp6Zsk/H7txQfXK2VrWgBpci8hIQFDhw7FunXrAAAtWrTApk2b4OzsLHGygsfihoiIiqU0Vfo4M8aGetjcv16m6+jJZKjmalWQsXLkxo0b8PHxwc2bN6Gnp4cpU6ZgwoQJ0NfPn/48hR2LGyIiKpY2nHkMABAC8CxVtC/dPHjwADdv3oSzszO2bNmCZs2aSR1JUixuiIioWFIo01tuzIyK5kehEAIymQwA0L59e6xevRrt2rWDg0Pu5pzSBUXzf5SIiIqlJ1GJmHfkLuJT0nK9r5vPYwEA/vU9cr2vgnblyhV888032LZtG9zd3QEA/fr1kzhV4cHihoiIiowdF59gz+VnebpPW3N5nu4vPwkhsHLlSgwbNgwpKSn4/vvvERQUJHWsQofFDRERFQmKNBXeJKaPPdOonB3aVs/9XUCWxobwrlI0LuPExsbiq6++wvbt2wEAbdu2xbJlyyROVTixuCEiokIvJU2JFj//hWfR6VMWVHKyQFcv3ZwXKTPBwcHw9fXF/fv3YWBggICAAIwYMaLYDMqnLRY3RERU6EXGK9SFjaWxAZpUyPtRfQur48ePo3Xr1lAoFChZsiS2b9+Ojz/+WOpYhRqLGyIiKjSEEAi6+ARhUYkay+OS0zsQGxno4erUVlJEk8zHH3+MihUrokyZMli7dm2xHHFYWyxuiIio0Lj5IhZjdl3L8vWietu2tm7cuIFKlSpBX18fJiYmOH78OGxsbNS3ftP7FY/vEiIiKhLi/99CY2lsgE6ebhleb16xaHT+zSkhBBYsWIAxY8Zg8uTJmDhxIgDA1tZW4mRFC4sbIiIqUEIIDNlyGSfvvcrwWppKAEifLXtKu6oFHU1SUVFR6N27N/bv3w8AuH79usZAfZR9LG6IiKhAJSqUH5ywsopL4Z/PKS/9888/8PPzw5MnTyCXyzF//nwMGjSIhU0OsbghIqICdf9lvPrxwWGNYWSgeTuznkyGkjZFYybu3FKpVPj5558xfvx4KJVKlCtXDkFBQahVq5bU0Yo0FjdERFRgUtKU6LziH/XzMvZmMDIonjNXA+kTXk6ePBlKpRJdu3bFL7/8AgsLC6ljFXksboiIqMAkK1RIVab3qxn5aYViXdgAQPny5bFkyRIIIdC/f39ehsojLG6IiCjfLfnzHk7ceaXuMAwAA5uWlTCRNFQqFX788Ud4e3vDy8sLANC/f3+JU+keFjdERJSvlCqBuUfuQvxb18Dewgh6xayVIiIiAj179sSRI0ewatUqXL9+HWZmZlLH0kksboiICOExyXiTqMiXfStVQl3YzPOpAVO5Aaq7WUFPr/gUN3/++Se6d++O8PBwmJiYYMqUKSxs8hGLGyKiYu7cw9fwW3VWo2Ulv7Ss7AgrE8P8P1AhoVQq8cMPP2D69OkQQqBq1aoICgpClSpVpI6m01jcEBEVcw9eJUAIQK6vByvT/Cs86pexhaVx8fnYiY2NRYcOHXDixAkAQN++fbF48WKYmhaP29ylVHy+y4iICMduReDorZcay+6/jAMANKtoj5W96kgRSyeZm5vDzMwMZmZmWLFiBXr06CF1pGKDxQ0RUTEyaudVRCVk3rfGshhdLsovaWlpSE1NhYmJCfT09LB+/XpERkaiYsWKUkcrVljcEBEVEyqVQKIifWLKfo1Ka/R9MdTXQ8daLlJF0wlPnz5Ft27dULp0aaxfvx5A+oSXnPSy4LG4ISIqBoIuPsGEPdfUA+j1buAB92IyxUFBOHDgAHr16oXXr18jJCQE06ZNg4eHh9Sxii29D69CRERF3d93X6kLGw9bUzhYGkmcSDekpqZi9OjRaNu2LV6/fo3atWsjODiYhY3E2HJDRKSDbr2IxbmHr9XPH0UmAABGt66IrxqXgYE+/7bNrbCwMPj5+eHMmTMAgKFDh2LOnDkwMmLhKDUWN0REOsh/7Xm8jEvJsNzaRM7CJg+oVCq0bt0at27dgpWVFdauXYsvv/xS6lj0fyxuiIh0jFIl1IVNq6qOMPx/MWNjJsdnHzlJGU1n6OnpYeHChZg8eTK2bNmC0qVLSx2J3sHihoioiJt/5C72X32ufv7uSMML/WrB2LB4z7ydVx4+fIgHDx7gk08+AQB88sknaNmyJfT02BJW2LC4ISIq4laffIgEhTLDcldrExgZ8IM3L+zatQt9+/YFAAQHB6Ns2fQZzVnYFE4sboiIJCKEwO3wOLzJYlC97EpVpTfVLO5aCw4W/3ZmreRkCVkxm3k7ryUnJ2PkyJFYunQpAKB+/fowNORgh4UdixsiIokcv/MSfQMv5tn+apcqAVdrkzzbX3F37949+Pr64vLlywCA0aNHY8aMGSxuigAWN0REEnkSlQQAsDAygEsui5JqblZwsTLOi1gEYNu2bfjqq68QFxcHW1tbbNiwAW3atJE6FmUTixsiomy4GBqFwH9CoVSJD6+cTaGvEwEATSraY2m32nm2X8q9c+fOIS4uDo0bN8aWLVvg5uYmdSTSAosbIqJsWPznffx191W+7NvWTJ4v+yXtCCHUfZRmz56NcuXK4euvv4aBAT8qixr+jxERZUNKWvrdSD513FDNzTrP9mukr4dWVTn2jNQ2bdqELVu2YN++fTAwMIBcLsfgwYOljkU5xOKGiCgbzj6MAgA0Km+P9jU4e7auSEhIwNChQ7Fu3ToAwLp16zBgwACJU1FusbghIsoGD1tThL5OhB7vrNYZN27cgI+PD27evAmZTIYpU6aox7Khok3y4mbp0qWYM2cOwsPDUaNGDSxevBheXl5Zrr9gwQIsX74cYWFhsLOzQ+fOnREQEABjY94lQERZC3udiL0hz5CWww7BbxJTAQDOvCOpyBNCIDAwEIMHD0ZSUhKcnJywZcsWNG/eXOpolEckLW62b9+OESNGYMWKFahXrx4WLFiAVq1a4c6dO3BwcMiw/pYtWzB27FisXbsWDRo0wN27d9G7d2/IZDLMmzdPgndAREXFrAO3cOhGeK73Y2Io+d+ElEvTpk3DtGnTAKRPobBp06ZMP3Oo6JIJIfLuvkYt1atXD3Xr1sWSJUsApM+y6u7ujqFDh2Ls2LEZ1h8yZAhu3bqFY8eOqZd9//33OHfuHE6dOpWtY8bGxsLKygoxMTGwtLTMmzdCRIVe99Vncfr+azQub4fSdmY52kcpWzP0bejBUX+LuFu3buHjjz/GmDFjMHbsWE6hUERo8/kt2Z8gCoUCly5dwrhx49TL9PT04O3tjTNnzmS6TYMGDbBp0yacP38eXl5eePjwIQ4cOICePXtmeZyUlBSkpKSon8fGxubdmyCifKVSCQzYcBGXn0Tnel+xSemXlTp7uqFDTddc74+KDiEErly5gpo1awIAKleujEePHsHGxkbaYJRvJCtuIiMjoVQq4ejoqLHc0dERt2/fznSbbt26ITIyEo0aNYIQAmlpaRg4cCDGjx+f5XECAgLUzY9EVLS8jEvBsdsv82x/+noylLU3z7P9UeEXGxuLr7/+GkFBQThx4gQaN24MACxsdFyRunh84sQJzJo1C8uWLUO9evVw//59DBs2DD/88AMmTZqU6Tbjxo3DiBEj1M9jY2Ph7u5eUJGJKBcE0q+a6+vJcGhY41zvr4SZHHbmRh9ekXTC5cuX4ePjg/v370NfXx+3bt1SFzek2yQrbuzs7KCvr4+IiAiN5REREXByynxAq0mTJqFnz57o378/AKBatWpISEjAV199hQkTJmR63dTIyAhGRvxlRlQU3XiWfhlZqRIo72ghcRoqKoQQWLZsGUaMGAGFQoGSJUti27ZtqF+/vtTRqIBI1otKLpfD09NTo3OwSqXCsWPHsvwGTExMzFDA6OvrA0j/ZiYi3ZKSppI6AhUx0dHR6NKlC4YMGQKFQoH27dvj8uXLLGyKGUkvS40YMQL+/v6oU6cOvLy8sGDBAiQkJKBPnz4AgF69esHV1RUBAQEAgHbt2mHevHmoVauW+rLUpEmT0K5dO3WRQ0RFx+PXCfjht1uIS07N9PXXCQoAQL3S7B9B2bN3717s2rULhoaG+OmnnzBs2DDe3VYMSVrc+Pr64tWrV5g8eTLCw8NRs2ZNHDp0SN3JOCwsTKOlZuLEiZDJZJg4cSKePXsGe3t7tGvXDjNnzpTqLRBRLuy/8hxHb0V8cD1HSw6cR9nj7++Pq1evomvXrqhbt67UcUgiko5zIwWOc0NUOMQmp2LOoTvYePYxGpe3g1/dkpmup68nQ8NytrAwNizghFQUREVFYeLEiQgICICVlZXUcSgfFYlxboio+HqToECj2X8iQZE+03YpW1O0re4scSoqas6cOQM/Pz+EhYUhJiYGmzdvljoSFRIclpGICtzTN0lIUCghkwGu1iZoXZWFDWWfSqXCnDlz0KRJE4SFhaFs2bL4/vvvpY5FhQhbbogo1x6+isfmc2FQZPPuptcJ6aOGO1ka4/TYFvkZjXRMZGQk/P39ceDAAQDpfTdXrlzJbgakgcUNEeXakuP3sTv4mdbbWRjzVxBlX0hICD7//HM8e/YMRkZGWLRoEQYMGMC7oSgD/mYholxL+n/fmWYV7VHdzTpb28gAfFLF8YPrEb3l5uYGAKhYsSKCgoJQvXp1iRNRYcXihog+6P7LePitPIPIeMV712tZ2RE9Py5VQKmoOIiNjVVfcrKzs8Phw4dRqlQpmJtzjjDKGjsUE9EHBT9+88HCxshAD9VceSsu5Z3jx4+jYsWKWL9+vXpZ1apVWdjQB7HlhqgYSk5V4tD1cMSlpGVr/eDHbwAAjcvbYb5vzUzXMZXrw1TOXymUe0qlEjNmzMD06dOhUqmwdOlS9OzZM9P5A4kyw99ERMXQprOPMeP3W1pvZ25kwFm1KV+9ePECPXr0wJ9//gkA6NOnDxYvXszChrTC4oaoGHqTmH6JqZStKao4Z+8WWkN9PfRrVDo/Y1Exd+TIEfTo0QMvX76EmZkZli9fjp49e0odi4ogFjdExcy+K8+x9PgDAECLSg6Y0q6qxImIgIcPH+Kzzz6DUqlEtWrVEBQUhEqVKkkdi4ooFjdExcymM4/Vj91LmEqYhOhfZcqUwZgxY/D69WvMnz8fJiYmUkeiIozFDVExolQJXApL7xw8qFlZ9GnoIW0gKtYOHjyIihUrokyZMgCAGTNmcEA+yhPsoUVUjPx06DaUKgEAqOVuzQ8SkkRqaipGjx6NNm3awM/PDwpFeh8wfj9SXmHLDVEx8vh1ovpxvdK2Eiah4iosLAx+fn44c+YMAMDLywtCCIlTka5hcUOkY5QqgZ//uIMnUYkZXgt5Eg0A+KHjR7AyNSzgZFTc7du3D71798abN29gZWWFNWvWoFOnTlLHIh3E4oZIx4Q8icbyEw/eu46NqbyA0hABCoUCY8eOxfz58wEAdevWxbZt29R9bYjyGosbIh2RkJIGRZoKr+NTAAB25kYY0rxshvVszI3waVVOWEkFRwiBv//+GwDw3XffYfbs2ZDLWWBT/mFxQ6QDDl0Px5AtwUhT/dt3oYSpIXo35KB7JB0hBGQyGYyMjBAUFIRr166hQ4cOUseiYoDFDZEOuBz2RqOwAdJn6CaSQkpKCkaOHAlra2v88MMPANLHseFlKCooLG6IipiYpFTsvPQUCe9Mennp/xNb9m9UGuPaVAYA6OvxtloqePfv34evry+Cg4Ohp6cHf39/lCtXTupYVMywuCEqYjafe4yfDt3J9DVTIwMWNSSZoKAg9O/fH3FxcbC1tcX69etZ2JAkWNwQFTGxSektNpWcLFC7VAn1cnMjA/SoV1KqWFSMJSUlYfjw4fjll18AAI0aNcLWrVvh5uYmcTIqrljcEBUCQggM2XoZ5x9FfXDd+OT04qZhOTtM+rxKfkcjei8hBLy9vfHPP/9AJpNh3LhxmDZtGgwM+PFC0uF3H1Eh8CYxFb9ffaHVNhUczfMpDVH2yWQyDBgwAPfu3cOmTZvw6aefSh2JiMUNUWGQplKpH//+bSPofWCOHTO5AUrackZvkkZiYiIeP36MypXTO6/37t0bHTp0QIkSJT6wJVHBYHFDVAgEXXiiflzZyRJ67BRMhdTNmzfh4+ODmJgYhISEwNY2fY4yFjZUmHBWcKJCID5FCQAw0JOxsKFCKzAwEHXq1MGNGzeQlpaG0NBQqSMRZYrFDVEhsOXcYwBA7wYe0gYhykR8fDz8/f3Rp08fJCUlwdvbGyEhIfD09JQ6GlGmWNwQFQKx/78DythQX+IkRJquXbuGunXrYsOGDdDT08OMGTNw+PBhODpyBGwqvNjnhkgiCSlpiIhNBgDoyQCVAPy83CVORaRp9uzZuH37NlxcXLB161Y0adJE6khEH8TihkgC8SlpaDT7T0Qnpmosl+uzMZUKl6VLl8LExASzZs2Cvb291HGIsoW/SYkkEB6TpC5sLI0NYGlsgOYV7WFvYSRxMiruLl++jFGjRkGI9IlYrayssGrVKhY2VKTkquUmOTkZxsbGeZWFqFj4NeQZTtx5BQAoYWqIy5M56BlJTwiB5cuXY/jw4VAoFKhSpQr69OkjdSyiHNG65UalUuGHH36Aq6srzM3N8fDhQwDApEmTsGbNmjwPSKRL4pJTMXx7CPZcfgYAMDfmlWGSXkxMDHx8fDB48GAoFAq0a9cOHTp0kDoWUY5pXdzMmDEDgYGB+OmnnyCXy9XLP/roI6xevTpPwxHpmpQ0FVTprf0Y3LwsFvjWkjYQFXsXLlxArVq1sHPnThgaGmLevHn49ddfYWNjI3U0ohzTurjZsGEDVq5cie7du0Nf/9/bVmvUqIHbt2/naTgiXfP27igAGNWqEjxLcVRXks7atWvRsGFDPHr0CB4eHjh16hSGDx8O2Qem/yAq7LQubp49e4Zy5cplWK5SqZCamprJFkT01pOoRKkjEKmVK1cOSqUSX375JS5fvgwvLy+pIxHlCa0v+FepUgUnT55EqVKlNJbv3LkTtWqxiZ0oK0kKJfZfSZ/5u6a7tbRhqNiKjo6GtbU1AKBJkyY4d+4cPD092VpDOkXr4mby5Mnw9/fHs2fPoFKpsHv3bty5cwcbNmzAb7/9lh8ZiXTCmlMP8fu19OLG2JCjMFDBUqlUmDdvHmbOnIkzZ86gUqVKAIA6depInIwo72n9G7ZDhw7Yv38/jh49CjMzM0yePBm3bt3C/v378cknn+RHRiKd8DpBoX78bcvyEiah4iYyMhLt27fHqFGjEB0djY0bN0odiShf5eg+1MaNG+PIkSN5nYVIp607HQog/S6pBmXtpA1DxcapU6fQtWtXPH36FEZGRli4cCG++uorqWMR5SutW27KlCmD169fZ1geHR2NMmXK5EkoIl2TplSpH5cwlb9nTaK8oVKpEBAQgGbNmuHp06eoUKECzp07h6+//pr9a0jnad1yExoaCqVSmWF5SkoKnj17liehiHRFSpoS15/FahQ3nT3dJExExUVgYCDGjx8PAOjRoweWL18Oc3NziVMRFYxsFzf79u1TPz58+DCsrKzUz5VKJY4dOwYPD488DUdU1H298ZJ6qoW3+FczFYRevXph27Zt8PPzQ58+ffh9R8VKtoubjh07Akj/xezv76/xmqGhITw8PDB37tw8DUdU1D1+nT6ujZOlMYwN9fBxGVtYmRhKnIp0kVKpxJo1a9C7d2/I5XIYGBjg8OHDLGqoWMp2caNSpTerly5dGhcuXICdHTtEEv1XQkoa5h+5i8j4FADAy/+PSLykWy3U8eBw9pQ/wsPD0b17d/z555+4ffs25s2bB4CthFR8ad3n5tGjR/mRg0gnHL/zEqtPZfwZsWYnYsonR48eRY8ePRAREQFTU1MOpkqEHN4KnpCQgL/++gthYWFQKBQar3377bd5EoyoKIpOTJ+CpIy9Gbp5lQQAeNiaoZwDO3JS3kpLS8O0adMwc+ZMCCFQrVo1BAUFqQfnIyrOtC5uLl++jDZt2iAxMREJCQmwsbFBZGQkTE1N4eDgwOKGiq2dl55i4t7rAAD3Eqbo35hDI1D+ePbsGbp164a///4bADBgwAAsXLgQJiYmEicjKhy0Hudm+PDhaNeuHd68eQMTExOcPXsWjx8/hqenJ37++ef8yEhUJJx/9O/4T00q2EuYhHRdUlISLl++DHNzc2zZsgUrV65kYUP0Dq1bbkJCQvDLL79AT08P+vr6SElJQZkyZfDTTz/B398fX375ZX7kJCrU4pJTEXTxKQBgxCcV0K9RaYkTka4RQqg7CJcrVw5BQUEoW7YsypfnVB5E/6V1y42hoSH09NI3c3BwQFhYGADAysoKT548ydt0REXE1vNh6sfmRjnqykaUpSdPnqBp06Y4evSoelnr1q1Z2BBlQevfwrVq1cKFCxdQvnx5NG3aFJMnT0ZkZCQ2btyIjz76KD8yEhV6MUmp6scda7lKmIR0zf79+9G7d29ERUVh8ODBuHnzJvT19aWORVSoaV3czJo1C3FxcQCAmTNnolevXhg0aBDKly+PNWvW5HlAovwkhMCQLZdx6fGbXO0nLjm9uOnT0AM2Zrztm3JPoVBg3Lhx6jFr6tSpg+3bt7OwIcoGrYubOnXqqB87ODjg0KFDeRqIqCC9ik/B79de5Nn+eMs35YXQ0FD4+vri/PnzAIBhw4Zh9uzZMDIykjgZUdGQZ50DgoODMXnyZPz2229abbd06VLMmTMH4eHhqFGjBhYvXgwvL68s14+OjsaECROwe/duREVFoVSpUliwYAHatGmT27dAxUxccipO3YsEAOjJgH1DGuVqf6ZyfZSxZ3FDufPkyRPUqlUL0dHRsLa2xrp169TT3xBR9mhV3Bw+fBhHjhyBXC5H//79UaZMGdy+fRtjx47F/v370apVK60Ovn37dowYMQIrVqxAvXr1sGDBArRq1Qp37tyBg4NDhvUVCgU++eQTODg4YOfOnXB1dcXjx49hbW2t1XGJAGD49is4eisCAGCgp4ePXK0+sAVR/nNzc0O7du1w7949bNu2DaVKlZI6ElGRIxNCiOysuGbNGgwYMAA2NjZ48+YNbG1tMW/ePAwdOhS+vr4YNmwYKleurNXB69Wrh7p162LJkiUA0uevcnd3x9ChQzF27NgM669YsQJz5szB7du3YWiYs8kHY2NjYWVlhZiYGFhaWuZoH6QbPl98EtefxaKsvRk6e7pjULOyUkeiYurBgwewtraGra0tACAxMRGGhoY5/j1HpIu0+fzO9q3gCxcuxOzZsxEZGYmgoCBERkZi2bJluHbtGlasWKF1YaNQKHDp0iV4e3v/G0ZPD97e3jhz5kym2+zbtw/169fH4MGD4ejoiI8++gizZs2CUqnM8jgpKSmIjY3V+CI6/ygK15+lfy9M+rwKCxuSTFBQEGrVqoU+ffrg7d+apqamLGyIciHbxc2DBw/QpUsXAMCXX34JAwMDzJkzB25ubjk6cGRkJJRKJRwdHTWWOzo6Ijw8PNNtHj58iJ07d0KpVOLAgQOYNGkS5s6dixkzZmR5nICAAFhZWam/3N3dc5SXdMuqkw/Vj+0t2EmTCl5ycjIGDRoEX19fxMXFISoqin98EeWRbBc3SUlJMDU1BQDIZDIYGRnB2dk534JlRqVSwcHBAStXroSnpyd8fX0xYcIErFixIsttxo0bh5iYGPUXBxokAIiMTwEAdPZ0Q1UX9rWhgnX37l18/PHH6t9d48aNw4kTJ2Blxe9ForygVYfi1atXw9w8/W6QtLQ0BAYGws7OTmOd7E6caWdnB319fURERGgsj4iIgJOTU6bbODs7w9DQUGOch8qVKyM8PBwKhQJyecbxRYyMjHj7JGkIeRKNy2HRAIB6pW2kDUPFzubNm/H1118jISEB9vb22Lhxo9Y3YxDR+2W7uClZsiRWrVqlfu7k5ISNGzdqrCOTybJd3Mjlcnh6euLYsWPq2xxVKhWOHTuGIUOGZLpNw4YNsWXLFqhUKvUUEHfv3oWzs3OmhQ1RZu6E/9v0X6+0rYRJqLhJTEzExIkTkZCQgGbNmmHz5s1wcXGROhaRzsl2cRMaGprnBx8xYgT8/f1Rp04deHl5YcGCBUhISECfPn0AAL169YKrqysCAgIAAIMGDcKSJUswbNgwDB06FPfu3cOsWbOyXVBR8fPgVTx2XHyKNKVKvexORPoI296VHVDS1lSqaFQMmZqaYvv27eo+gxxtmCh/SDrDn6+vL169eoXJkycjPDwcNWvWxKFDh9SdjMPCwtQtNADg7u6Ow4cPY/jw4ahevTpcXV0xbNgwjBkzRqq3QIXcz4fv4OD1zDuom3GCSyoA69evh1KpRN++fQEAXl5e7x2olIhyL9vj3OgKjnNTvPRaex5/332FFpUcUMHRQr1cri9DZ093ttxQvomPj8fgwYOxYcMGGBkZ4erVq6hQoYLUsYiKLG0+v/mnK+msA9de4O+7rwAAn1d3xpe1czZsAZG2rl27Bh8fH9y+fRt6enqYOHEiypblWEpEBYXFDemsY7deqh9XcmIrHeU/IQTWrFmDoUOHIjk5GS4uLtiyZQuaNm0qdTSiYoXFDRVZ9yLi1Ld0Zyb0dQIAYGiLcqjiwuKG8pcQAv7+/uq7SFu3bo0NGzbA3t5e4mRExU+OipsHDx5g3bp1ePDgARYuXAgHBwccPHgQJUuWRNWqVfM6I1EGKpWAzy9n8CYx9YPrljDlMAGU/2QyGcqXLw99fX3MnDkTo0aN0rghgogKjtbFzV9//YXPPvsMDRs2xN9//42ZM2fCwcEBV65cwZo1a7Bz5878yEmkQSmEurBpXN4OhvqZf4hYmxiibfWCHUmbig8hBKKjo1GiRAkAwPjx49G+fXvUqFFD4mRExZvWxc3YsWMxY8YMjBgxAhYW/9590qJFC/Xs3kQ5df1ZDKb/dhNJiqwnQwUA1Ts3+S3pWhtWppxkkApWTEwMBgwYgDt37uDs2bMwMTGBvr4+CxuiQkDr4ubatWvYsmVLhuUODg6IjIzMk1BUfO25/AznH0Vle30rE0OYyDkQGhWsixcvwtfXFw8fPoSBgQFOnz4Nb29vqWMR0f9pXdxYW1vjxYsXKF26tMbyy5cvw9XVNc+CUfGkSEsfSbhtdWd09vzwrduVnSwhN2C/BioYQggsXrwYI0eORGpqKkqVKoXt27ejXr16UkcjondoXdz4+flhzJgx2LFjB2QyGVQqFU6fPo2RI0eiV69e+ZGRipFdwU8BAO4lTNG8ooPEaYj+9ebNG/Tt2xd79+4FAHTs2BFr165V97chosJD6z95Z82ahUqVKsHd3R3x8fGoUqUKmjRpggYNGmDixIn5kZGKkXIO6bPOm/FSExUy33zzDfbu3Qu5XI5FixZh9+7dLGyICimtW27kcjlWrVqFSZMm4fr164iPj0etWrVQvnz5/MhHxcjr+BRcfRoDAKjqynFpqHCZPXs2Hjx4gOXLl8PT01PqOET0HloXN6dOnUKjRo1QsmRJlCxZMj8yUTG15/Iz9WMrE45NQ9J6/fo19u/fj969ewMASpYsiXPnzkEmk0kbjIg+SOvipkWLFnB1dUXXrl3Ro0cPVKlSJT9ykY5QpKmQplJla934lDQAgKlcH7VLWudjKqL3O336NPz8/PD06VPY2tqiXbt2AMDChqiI0Lq4ef78ObZt24atW7fixx9/RPXq1dG9e3d07doVbm6cmJD+dfp+JPqtv4Dk1OwVN2+1q+7CDxGShEqlwk8//YSJEydCqVSifPnycHd3lzoWEWlJ6w7FdnZ2GDJkCE6fPo0HDx6gS5cuWL9+PTw8PNCiRYv8yEhF1MXQN1oXNob6MtQva5tPiYiy9vLlS7Rp0wbjxo2DUqlEt27dcOnSJdSsWVPqaESkpVxNnFm6dGmMHTsWNWrUwKRJk/DXX3/lVS4qgv66+wq3X8Sqn198nD4Yn28dd0xtn705x/T0ACMD3ilFBeuvv/5C165d8eLFCxgbG2PJkiXo27cvWxCJiqgcFzenT5/G5s2bsXPnTiQnJ6NDhw4ICAjIy2xUhLyKS0HvdefxzqwIaubGBhxFmAq1Fy9e4MWLF6hcuTKCgoLw0UcfSR2JiHJB6+Jm3Lhx2LZtG54/f45PPvkECxcuRIcOHWBqapof+aiIiE9JgxCAgZ4MHWr+O1K1iVwPvRt4SBeMKAtCCHXLjJ+fHxQKBTp16gQzMzOJkxFRbmld3Pz9998YNWoUfHx8YGdnlx+ZqIg5dS8SE/ZeAwCYGOpjrg8nDqTC7dixYxg5ciQOHjwIJycnAOAI60Q6ROvi5vTp0/mRg4qwfVee4fHrRABAaXv+1UuFl1KpxLRp0zBjxgwIITBt2jQsX75c6lhElMeyVdzs27cPn332GQwNDbFv3773rtu+ffs8CUaFQ5pShYuP3yBJocxynefRyQCAXvVLYXybygUVjUgrz58/R7du3dQ3PvTv3x9z586VOBUR5YdsFTcdO3ZEeHg4HBwc0LFjxyzXk8lkUCqz/hCkomf1qUf48eDtbK3rVsIExobsOEyFz+HDh9GjRw9ERkbC3Nwcv/zyC7p16yZ1LCLKJ9kqblTvjDCryuZos6QbnkcnAQAcLIzgZGWc5XpWJoZoXdW5oGIRZduOHTvg4+MDAKhRowaCgoJQoUIFiVMRUX7Sus/Nhg0b4OvrCyMjI43lCoUC27ZtY6c8HZCcqsQPv93Ei5hk3AmPAwD41XXHiE8rSpyMSHutW7dGhQoV4O3tjblz58LYOOsinYh0g0yIzEYmyZq+vj5evHgBBwcHjeWvX7+Gg4NDob8sFRsbCysrK8TExMDSkjNPZ+avu6/gv/a8xrLpHaqiV30PaQIRaens2bOoV6+e+lbv2NhY/rwTFXHafH5rPf3Cu2NDvOvp06ewsrLSdndUyEQnKhARk95B2N3GBD91ro4VPWrDty7n16HCT6FQYOTIkahfvz4WLFigXs7Chqh4yfZlqVq1akEmk0Emk6Fly5YwMPh3U6VSiUePHqF169b5EpIKxun7kei19jyUqvTGPBszI/jUYVFDRUNoaCj8/Pxw7tw5AMCzZ88kTkREUsl2cfP2LqmQkBC0atUK5ubm6tfkcjk8PDzQqVOnPA9IBefG8xgoVQJ6MsDYUB9tqzlJHYkoW/bu3Ys+ffogOjoa1tbWWLdu3Xvv7CQi3Zbt4mbKlCkAAA8PD/j6+rJTng6JSUrFprOPcfLeKwBAx1qumOdTU9pQRNmQkpKC0aNHY9GiRQCAevXqYdu2bfDw8JA2GBFJSuu7pfz9/fMjB0lox8UnmHP4jvq5uVGuJosnKjA3b97EsmXLAADff/89Zs2aBblcLnEqIpJatj7FbGxscPfuXdjZ2aFEiRKZdih+KyoqKs/CUcGIT0kDAFRyssAnVRzR1aukxImIsqdWrVpYvHgx3Nzc8Pnnn0sdh4gKiWwVN/Pnz4eFhYX68fuKGyqcIuNT4LfyLF78f1C+dymU6QMzepYqge85lg0VYsnJyRgzZgz69euH6tWrAwAGDhwocSoiKmyyVdy8eymqd+/e+ZWF8lFIWDTuv4x/7zofufJWfiq87t69Cx8fH1y5cgV//PEHrl27pnHXJhHRW1r/ZggODoahoSGqVasGAPj111+xbt06VKlSBVOnTuX17kKukpMFVvask2G5saEeHCzZSZwKpy1btuDrr79GfHw87O3tsWDBAhY2RJQlrQfx+/rrr3H37l0AwMOHD+Hr6wtTU1Ps2LEDo0ePzvOAlLeMDPVR0tY0wxcLGyqMEhMTMWDAAHTv3h3x8fFo2rSpejgKIqKsaF3c3L17FzVr1gSQPiFd06ZNsWXLFgQGBmLXrl15nY+Iiqnw8HDUq1cPq1evhkwmw+TJk3H06FG4uLhIHY2ICjmt23WFEOqZwY8ePaq+Q8Hd3R2RkZF5m47yxNmHr9F/w0WpYxBpxd7eHg4ODnB0dMTmzZvRsmVLqSMRURGhdXFTp04dzJgxA97e3vjrr7+wfPlyAMCjR4/g6OiY5wEp97acC1M/dublJyrEEhISoK+vD2NjY+jr62Pz5s0AACcnjpZNRNmn9WWpBQsWIDg4GEOGDMGECRNQrlw5AMDOnTvRoEGDPA9IOfMsOgnXn8Xg+rMYvElUAACaVbTHXJ8aEicjytz169dRt25dDB8+XL3MycmJhQ0RaU0mhBB5saPk5GTo6+vD0NAwL3aXb7SZMr2oOvPgNbquOpth+fQOVdGrvkfBByJ6DyEE1q5diyFDhiA5ORkuLi64evUqbG1tpY5GRIWINp/fOb6X8tKlS7h16xYAoEqVKqhdu3ZOd0V57GFk+ng2RgZ6sDFLvzW/hKkcTcrbSxmLKIO4uDgMGjRIffmpVatW2LhxIwsbIsoVrYubly9fwtfXF3/99Resra0BANHR0WjevDm2bdsGe3t+gErpwat4TP71BoD0y1C/ZDKmDVFhcOXKFfj4+ODu3bvQ19fHjBkzMHr0aOjpaX21nIhIg9a/RYYOHYr4+HjcuHEDUVFRiIqKwvXr1xEbG4tvv/02PzKSFn756wGUqvQrjVYmhfsSIRVfKSkpaNOmDe7evQs3Nzf89ddfGDt2LAsbIsoTWrfcHDp0CEePHkXlypXVy6pUqYKlS5fi008/zdNwpL3k1PTb9F2tTTCS80RRIWVkZITly5dj1apVCAwM5GUoIspTWhc3KpUq007DhoaG6vFvSHr9GpXmqMNUqFy6dAlv3ryBt7c3AKB9+/Zo164dJ+IlojyndRtwixYtMGzYMDx//ly97NmzZxg+fDgH2SKiDIQQWLx4MRo0aABfX188efJE/RoLGyLKD1oXN0uWLEFsbCw8PDxQtmxZlC1bFqVLl0ZsbCwWL16cHxkpm+6/jMO+K88/vCJRAXnz5g06deqEb7/9FgqFAk2aNIG5ubnUsYhIx2l9Wcrd3R3BwcE4duyY+lbwypUrq5uaSTrfbA5WPzYyZMdMkta5c+fg5+eH0NBQyOVy/PzzzxgyZAhba4go32lV3Gzfvh379u2DQqFAy5YtMXTo0PzKRTkQnZgKAPAqbYO21ZwlTkPFlRAC8+fPx5gxY5CWloYyZcogKCgInp6eUkcjomIi23/eL1++HF27dsXFixdx7949DB48GKNGjcrPbJRN4THJ6LT8H0TGpwAAprSrAmtTucSpqLiSyWS4ffs20tLS0KVLFwQHB7OwIaICle3iZsmSJZgyZQru3LmDkJAQrF+/HsuWLcvPbJRNp+9H4tLjN1AJQG6gB2crE6kjUTH07t2SCxcuxKZNm7B9+3ZYWVlJmIqIiqNsFzcPHz6Ev7+/+nm3bt2QlpaGFy9e5Eswyp6UNCVOP4gEANQqaY1To5urp1wgKggqlQqzZ8/G559/ri5wTExM0L17d/avISJJZLvPTUpKCszMzNTP9fT0IJfLkZSUlC/BKHsm7b2O3cHPAKTPH8WxbaggvXr1Cr169cKhQ4cAAL/++iu++OILiVMRUXGnVYfiSZMmwdTUVP1coVBg5syZGs3O8+bNy7t09EHPov8tLnt8XFLCJFTc/P333+jatSueP38OY2NjLFmyBB07dpQ6FhFR9oubJk2a4M6dOxrLGjRogIcPH6qfswm6YEUlKHD6/msAwEK/mmhRyVHiRFQcKJVKBAQEYMqUKVCpVKhcuTKCgoLw0UcfSR2NiAiAFsXNiRMn8jEG5cQfN8LVj23NjCRMQsXJN998g5UrVwIAevfujSVLlmhcsiYiklqhGOlt6dKl8PDwgLGxMerVq4fz589na7tt27ZBJpMVu6bw+JQ0hMck43WCAkD6HVINynLiQSoYgwYNgo2NDdavX49169axsCGiQkfrEYrz2vbt2zFixAisWLEC9erVw4IFC9CqVSvcuXMHDg4OWW4XGhqKkSNHonHjxgWYVnq3XsSi49LTSEn797bblpUcoKfHS4KUP5RKJc6fP4/69esDAGrWrInHjx9zGgUiKrQkb7mZN28eBgwYgD59+qBKlSpYsWIFTE1NsXbt2iy3USqV6N69O6ZNm4YyZcoUYFrp3XoRqy5sDPRkMJXro2Vl9rWh/PH8+XO0bNkSTZs2xYULF9TLWdgQUWEmacuNQqHApUuXMG7cOPUyPT09eHt748yZM1luN336dDg4OKBfv344efJkQUQtcLdexOLAtRdQCaGx/E54HACgcXk7bOxXT4poVEwcPnwYPXv2xKtXr2Bubo7nzzkpKxEVDZIWN5GRkVAqlXB01Gx5cHR0xO3btzPd5tSpU1izZg1CQkKydYyUlBSkpKSon8fGxuY4b0GauPc6Lj1+k+XrZnLJryiSjkpLS8OkSZPw448/AgBq1KiBoKAgVKhQQeJkRETZk6NPyJMnT+KXX37BgwcPsHPnTri6umLjxo0oXbo0GjVqlNcZ1eLi4tCzZ0+sWrUKdnZ22domICAA06ZNy7dM+SU+OQ0A0LqqE5ytNQfmM9TXg08dNylikY578uQJunbtitOnTwNIvzNq7ty5MDbm4JBEVHRoXdzs2rULPXv2RPfu3XH58mV1q0hMTAxmzZqFAwcOZHtfdnZ20NfXR0REhMbyiIgIODk5ZVj/wYMHCA0NRbt27dTL3g73bmBggDt37qBs2bIa24wbNw4jRoxQP4+NjYW7u3u2M0ph0bF7uBORfvmpV/1SaFAue4UcUW7t3r0bp0+fhqWlJVavXo0uXbpIHYmISGtadyieMWMGVqxYgVWrVsHQ0FC9vGHDhggODtZqX3K5HJ6enjh27Jh6mUqlwrFjx9R3ZryrUqVKuHbtGkJCQtRf7du3R/PmzRESEpJp0WJkZARLS0uNr8Ju7+Vn6sel7XmbLRWcoUOHYvTo0QgODmZhQ0RFltYtN3fu3EGTJk0yLLeyskJ0dLTWAUaMGAF/f3/UqVMHXl5eWLBgARISEtCnTx8AQK9eveDq6oqAgAAYGxtnGAXV2toaAHRmdFQhBB5GJgAA1vjX4QzflK8eP36MSZMmYdmyZTA3N4eenh5mz54tdSwiolzRurhxcnLC/fv34eHhobH81KlTObot29fXF69evcLkyZMRHh6OmjVr4tChQ+pOxmFhYdDTk/yO9QJz7VmM+nEJzu5N+ejXX39F7969ER0dDXNzcyxbtkzqSEREeULr4mbAgAEYNmwY1q5dC5lMhufPn+PMmTMYOXIkJk2alKMQQ4YMwZAhQzJ97UPTPgQGBubomIXVy9h/7+yq7mr1njWJckahUGD06NFYuHAhAMDLywujR4+WOBURUd7RurgZO3YsVCoVWrZsicTERDRp0gRGRkYYOXIkhg4dmh8Zi5WAg7cAADXcrWGgX3xarKhgPHz4EL6+vrh48SIA4Pvvv8esWbMgl7OVkIh0h9bFjUwmw4QJEzBq1Cjcv38f8fHxqFKlCkcszQOv41Pw4FV6fxtnS956S3nrxIkT6NChA2JjY9VzQ33++edSxyIiynM5HglOLpejSpUqeZml2FO+MxrxnC7VJUxCuqhixYowNjZGtWrVsHXr1kI/JAIRUU5pXdw0b94cMlnWkzT++eefuQpUnMUmpaofWxgbvmdNouyJjIxUD3jp7OyMv/76C2XLltUYxoGISNdo3amjZs2aqFGjhvqrSpUqUCgUCA4ORrVq1fIjY7GRkKKUOgLpkK1bt6JMmTLYuXOnelmlSpVY2BCRztO65Wb+/PmZLp86dSri4+NzHai4+vvuK2w+9xgA4GrNsW0o55KSkjBs2DCsWrUKALBhwwZ07txZ4lRERAUnz27H6dGjB9auXZtXuyt2xu+5hsM30qehsDThX9aUM7dv30a9evWwatUqyGQyTJo0Cbt375Y6FhFRgcqzqaXPnDnDyfVyIVGRfknKv34p+HmVlDgNFUUbNmzAoEGDkJiYCEdHR2zatAne3t5SxyIiKnBaFzdffvmlxnMhBF68eIGLFy/meBC/4u7hq3hEJSgAAF3rlUQlp8I//xUVLsHBwfD39wcAtGjRAps3b8508lkiouJA6+LGykpz1Fw9PT1UrFgR06dPx6effppnwYqTkCfR6sclbUylC0JFVu3atfH999/DysoK48ePh76+vtSRiIgko1Vxo1Qq0adPH1SrVg0lSpTIr0zFTlxyGgCgQVlbmMrz7Eoh6TAhBDZs2ICWLVvCzc0NAPDzzz9LnIqIqHDQqkOxvr4+Pv300xzN/k1ZO/vwNQAgJU0lcRIqCuLi4tCzZ0/07t0bXbt2RVpamtSRiIgKFa3vlvroo4/w8OHD/MhSbNn8f/Zva94lRR9w5coV1KlTB5s3b4a+vj7atm0LPT3OQUZE9C6tfyvOmDEDI0eOxG+//YYXL14gNjZW44u0s+DoXWw+FwYAqObGWcApc0II/PLLL6hXrx7u3r0LNzc3/PXXXxg7diyLGyKi/8h2B4/p06fj+++/R5s2bQAA7du315iGQQgBmUwGpZKj7GpjzclH6selbNmZmDKKi4tD//79ERQUBAD4/PPPERgYCFtbW4mTEREVTtkubqZNm4aBAwfi+PHj+ZmnWElUpCEuJb2/xC89PfFpFUeJE1FhpK+vj5s3b8LAwAA//vgjRowY8d753YiIirtsFzfi/zNWN23aNN/CFDdfb7ykflzF2ZIfWKQmhIAQAnp6ejA1NUVQUBBiYmLw8ccfSx2NiKjQ0+piPT9889aTqEQAQGk7M7iV4HxSlC46OhqdO3fG7Nmz1csqV67MwoaIKJu0GlSlQoUKHyxwoqKichWoOAl9nV7c/NylOgtHAgCcP38evr6+CA0NxcGDB9G3b184OvJyJRGRNrQqbqZNm5ZhhGLKmZikVPXjEqZyCZNQYSCEwIIFCzBmzBikpqaiTJky2L59OwsbIqIc0Kq48fPzg4ODQ35lKVbSlP8O2FfG3lzCJCS1qKgo9O7dG/v37wcAdO7cGatXr+YfEkREOZTt4oaXTfLW5bBoqSNQIaBQKPDxxx/j3r17MDIywvz58zFw4ED+vBER5UK2OxS/vVuK8sbTN4lSR6BCQC6X47vvvkP58uVx9uxZDBo0iIUNEVEuZbu4UalUvCSVh8JjUwAAbas7S5yEClpkZCRu3rypfj5o0CCEhISgZs2a0oUiItIhHLddIteeRQMAYt/pWEy67+TJk6hRowbatWuHmJgYAOmXfE1NOTo1EVFeYXEjERszIwBAGTsziZNQQVCpVJg5cyaaNWuG58+fQy6X49WrV1LHIiLSSVrdLUV55/T9SABAKVsWN7ouIiICPXv2xJEjRwAA/v7+WLp0KczM+H9PRJQf2HIjEY//T5IZm8zLUrrszz//RM2aNXHkyBGYmpoiMDAQgYGBLGyIiPIRW24kcvNFLACgkpOFxEkoP82fPx/h4eGoWrUqgoKCUKVKFakjERHpPLbcSOBJVCKSU9MH8dPX43+BLlu3bh1GjhyJ8+fPs7AhIiog/GSVwKv4FPXj+mVtJUxCee2PP/7AyJEj1c/t7OwwZ84c3g1FRFSAeFlKAhdD0ycXdbcxgbkR/wt0QVpaGqZMmYKAgAAIIdCgQQN8+eWXUsciIiqW+MkqgfOP0oubiNiUD6xJRcHTp0/RrVs3nDx5EgAwcOBAfPbZZxKnIiIqvljcSCA2KQ0AMLhZOYmTUG4dOHAAvXr1wuvXr2FhYYHVq1fDx8dH6lhERMUa+9wUsOvPYnD+/5elbMzlEqeh3Jg1axbatm2L169fw9PTE5cvX2ZhQ0RUCLC4KWAPXsWrHzcqZydhEsotT09PyGQyDB06FKdPn0bZsmWljkREROBlqQIX8iQaQHphU5pTLxQ5L1++VE8g26pVK9y4cQOVK1eWOBUREb2LLTcF7NitlwCA+JQ0iZOQNhQKBYYPH46KFSvi4cOH6uUsbIiICh8WNwXMwji9sayzp5vESSi7Hj16hEaNGmHBggWIjo7GwYMHpY5ERETvweKmAAkhcON5+rQL7jYc1K0o2LVrF2rVqoULFy7AxsYG+/btw+DBg6WORURE78HipgClpKnUj12tTSRMQh+SnJyMIUOGoHPnzoiJiUGDBg1w+fJltGvXTupoRET0ASxuClBUgkL92MnKWMIk9CGLFi3C0qVLAQBjxozBiRMnULJkSYlTERFRdvBuqQIUcPC2+rGBnkzCJPQhw4YNw/Hjx/Htt99ytGEioiKGLTcFKC45FQBQw80Kxob6EqehdyUlJeHnn39GWlr6XWxGRkY4ePAgCxsioiKILTcF6PT9SABAz/oe0gYhDbdv34aPjw+uXbuG6OhozJgxQ+pIRESUC2y5KUBv75BKUnCMm8Ji48aNqFOnDq5duwZHR0c0a9ZM6khERJRLLG4KUEpq+t1SZe3NJU5CCQkJ6Nu3L3r16oWEhAS0aNECISEh8Pb2ljoaERHlEoubAvQsOgkAoBRC4iTF261bt+Dl5YV169ZBT08P06ZNwx9//AEnJyepoxERUR5gn5sCZGFkgLiUNNiaGUkdpVhTqVR49OgRnJ2dsWXLFl6KIiLSMSxuCkiqUoW4/88nZSLnnVIFTalUQl8//bxXrVoVe/bsQa1atdSTYBIRke7gZakCciE0Sv3Y0pg1ZUG6cuUKqlevjlOnTqmXtWrVioUNEZGOYnFTQBTvTL1ga87LUgVBCIFffvkF9erVw82bNzFq1CgI9nciItJ5LG4KyIzfbwEAqjhbSpykeIiNjUXXrl0xcOBApKSkoE2bNti/fz9kMo4MTUSk61jcFBCVKr3FwNZcLnES3RccHAxPT09s374dBgYGmDNnDvbv3w87OzupoxERUQFg548C8jAyAQAwtEV5iZPotuvXr6N+/fpQKBQoWbIktm3bhvr160sdi4iIChCLmwKQ+M6IxMaGbCzLT1WrVsXnn3+OtLQ0rFu3DjY2NlJHIiKiAlYoPmmXLl0KDw8PGBsbo169ejh//nyW665atQqNGzdGiRIlUKJECXh7e793/cLg7cjEAFDVxUrCJLrp4sWLiImJAQDIZDJs2rQJe/fuZWFDRFRMSV7cbN++HSNGjMCUKVMQHByMGjVqoFWrVnj58mWm6584cQJdu3bF8ePHcebMGbi7u+PTTz/Fs2fPCjh59qUq/y1u2J017wghMH/+fDRo0ABfffWV+k4oExMTdhwmIirGJC9u5s2bhwEDBqBPnz6oUqUKVqxYAVNTU6xduzbT9Tdv3oxvvvkGNWvWRKVKlbB69WqoVCocO3asgJNn38u4FPVjfubmjaioKHTs2BEjRoxAamoqVCoVFAqF1LGIiKgQkLS4USgUuHTpksZkhXp6evD29saZM2eytY/ExESkpqYW6ksQbwsaKxNDtijkgTNnzqBmzZrYt28f5HI5li5diqCgIBgZcfwgIiKSuENxZGQklEolHB0dNZY7Ojri9u3b2drHmDFj4OLikuVszikpKUhJ+bflJDY2NueBc4mdiXNHpVLh559/xvjx46FUKlGuXDkEBQWhVq1aUkcjIqJCpEh/2v7444/Ytm0b9uzZA2Nj40zXCQgIgJWVlfrL3d29gFNSXomOjsbChQuhVCrRtWtXBAcHs7AhIqIMJC1u7OzsoK+vj4iICI3lERERcHJyeu+2P//8M3788Uf88ccfqF69epbrjRs3DjExMeqvJ0+e5El2bSSnKgv8mLrIxsYGW7duxcqVK7F582ZYWFhIHYmIiAohSYsbuVwOT09Pjc7AbzsHv2/gtZ9++gk//PADDh06hDp16rz3GEZGRrC0tNT4KmgvY9Mvi0XEpnxgTXqXSqXCzJkzsWnTJvWyJk2aYMCAAey7REREWZJ8EL8RI0bA398fderUgZeXFxYsWICEhAT06dMHANCrVy+4uroiICAAADB79mxMnjwZW7ZsgYeHB8LDwwEA5ubmMDc3l+x9vM/bz2FXaxNpgxQhERER6NmzJ44cOQJTU1M0b94crq6uUsciIqIiQPLixtfXF69evcLkyZMRHh6OmjVr4tChQ+pOxmFhYdDT+7eBafny5VAoFOjcubPGfqZMmYKpU6cWZPRsG7gpGABgZ8G7ebLj+PHj6NatG8LDw2FiYoIlS5bAxcVF6lhERFREyMTbkc+KidjYWFhZWSEmJqbALlGVG38AaSqBgU3LYuxnlQrkmEWRUqnEjBkzMH36dKhUKlStWhVBQUGoUqWK1NGIiEhi2nx+S95yo+uEEEj7/4zgfRp6SBumEEtLS0Pr1q3V/a/69euHRYsWwdTUVOJkRERU1BTpW8GLgvsv49WPjQ31JUxSuBkYGKBu3bowMzPDpk2bsHr1ahY2RESUIyxu8lmi4t/bwK1MDCVMUvikpaXh1atX6ufTp0/HlStX0L17dwlTERFRUcfipoDwTilNT58+RfPmzdG2bVv1nFCGhoYoW7asxMmIiKioY3FDBe7AgQOoWbMmTp06hdu3b+P69etSRyIiIh3C4iafFatb0T4gNTUVo0ePRtu2bfH69WvUrl0bwcHBqF27ttTRiIhIh/BuqXz2+HUCAE7B8PjxY/j5+eHs2bMAgKFDh2LOnDmcyZuIiPIci5t8ZmSQ3jj2OkEhcRJp9e/fH2fPnoWVlRXWrl2LL7/8UupIRESko3hZKp/9dvUFAKCuRwmJk0hr+fLl8Pb2xuXLl1nYEBFRvmJxk8+eRCUCAGKSUiVOUrAePXqE1atXq5+XK1cOR44cQenSpSVMRURExQEvS+WzVGV6l+KhLcpLnKTg7Nq1C/369UNsbCw8PDzg7e0tdSQiIipG2HKTz26+iAUAGOrLJE6S/5KTkzFkyBB07twZMTEx+Pjjj1G+fPEp6oiIqHBgcZPPnK2MAQAWxro9OvH9+/fRoEEDLF26FAAwevRo/PXXXyhVqpTEyYiIqLjhZal89iImGYBuT72wY8cO9OvXD3FxcbC1tcWGDRvQpk0bqWMREVExxeKmgBjq624jWXx8POLi4tC4cWNs2bIFbm5uUkciIqJijMVNAbEzl0sdIU+lpaXBwCD926d3794wNzfHF198oV5GREQkFd1tTqB8s3HjRlSvXh2vX78GAMhkMnTp0oWFDRERFQosbijbEhIS0LdvX/Tq1Qu3bt3CokWLpI5ERESUAf/UzkcRsclSR8gzN27cgI+PD27evAmZTIYpU6Zg4sSJUsciIiLKgMVNPvr58B31Y0ODotlIJoRAYGAgBg8ejKSkJDg5OWHLli1o3ry51NGIiIgyVTQ/cYuIt1Mu1HC3hmURHedm2bJl6Nu3L5KSkvDJJ58gJCSEhQ0RERVqLG4KgE+dontrdPfu3VGuXDnMnDkThw4dgqOjo9SRiIiI3ouXpUiDEAJHjx6Ft7c3ZDIZrK2tce3aNRgbG0sdjYiIKFvYckNqsbGx6NatGz799FOsWrVKvZyFDRERFSVsuSEAwOXLl+Hj44P79+/DwMAASUlJUkciIiLKERY3xZwQAsuWLcOIESOgUChQsmRJbNu2DfXr15c6GhERUY6wuCnGoqOj0b9/f+zatQsA0L59e6xbtw42NjYSJyMiIso59rkpxq5du4Y9e/bA0NAQ8+fPx969e1nYEBFRkceWm3yUqlRJHeG9GjdujCVLlqBOnTqoW7eu1HGIiIjyBFtu8okQAsfvvPr/Y4nD/F9UVBS6deuGO3f+HTl50KBBLGyIiEinsOUmn6Qq/61oqrpYSpgk3ZkzZ+Dn54ewsDDcv38f586dg0wmkzoWERFRnmPLTT4R+Le4KWNvLlkOlUqFOXPmoEmTJggLC0PZsmWxYsUKFjZERKSz2HKTT24+j1U/lutLU0NGRkbC398fBw4cAAD4+vpi5cqVsLSUviWJiIgov7C4ySfJqf92JjaR6xf48e/fv49mzZrh2bNnMDY2xsKFCzFgwAC22BARkc5jcZMPxu66it3BzwAA5RykuSRVqlQplCpVCubm5ggKCkL16tUlyUFERFTQWNzkg/1XnkPx/9vAa7hZF9hxX716BSsrK8jlchgaGmLnzp2wsLCAubl0fX6IiIgKGjsU5zEhBBIUSgDArkH18XOXgmkxOX78OKpXr47x48erlzk7O7OwISKiYofFTR67/uzfjsQu1ib53sdFqVRi2rRp8Pb2Rnh4OA4dOoTExMR8PSYREVFhxuImj0XGp6gfO1uZ5OuxXrx4gU8//RRTp06FSqVC3759cf78eZiamubrcYmIiAoz9rnJYxGxyQCA6m5W+XqcI0eOoEePHnj58iXMzMywfPly9OzZM1+PSUREVBSwuMljKWnpHYnvRsTl2zGio6PRpUsXxMTEoFq1aggKCkKlSpXy7XhERERFCYubPKb3/y42dT3yb3Zta2trrFixAsePH8eCBQtgYpK/l7+IiIiKEhY3eWzdP6EAACODvB247+DBgzA2Nkbz5s0BAH5+fvDz88vTYxAREekCdijOY44WxgAAS+O8qRtTU1MxZswYtGnTBl27dkVERESe7JeIiEhXseUmDwkhcObhawBA80oOud5fWFgY/Pz8cObMGQBA586dYWWVvx2ViYiIijoWN3no3st49WNrU8Nc7Wvfvn3o3bs33rx5AysrK6xZswadOnXKbUSiYkcIgbS0NCiVSqmjENEHGBoaQl8/9906WNzkoZR3JstsUNYuR/tQKpUYNWoU5s+fDwCoW7cutm3bhjJlyuRJRqLiRKFQ4MWLFxzYkqiIkMlkcHNzy/Xo+ixu8oGzlTH09XI2MrGenh5evnwJAPjuu+8we/ZsyOXyvIxHVCyoVCo8evQI+vr6cHFxgVwuz/cRw4ko54QQePXqFZ4+fYry5cvnqgWHxU0hkZaWBgMDA8hkMixfvhzdu3fHZ599JnUsoiJLoVBApVLB3d2do3YTFRH29vYIDQ1Fampqroob3i0lsZSUFAwdOhSdOnWCEAIAYGFhwcKGKI/o6fHXHFFRkVetq2y5kdD9+/fh6+uL4OBgAMCpU6fQuHFjiVMREREVbfyTRiLbt29H7dq1ERwcDFtbW/z2228sbIiIiPIAi5s8FPLkzQfXSUpKwsCBA+Hn54e4uDg0atQIISEhaNu2bQEkJCLSXXfu3IGTkxPi4vJvbj/KubFjx2Lo0KEFciwWN3no8ev0201fxCRnuY6fnx9++eUXyGQyjB8/HsePH4ebm1tBRSSiQq53796QyWSQyWQwNDRE6dKlMXr0aCQnZ/y98ttvv6Fp06awsLCAqakp6tati8DAwEz3u2vXLjRr1gxWVlYwNzdH9erVMX36dERFReXzOyo448aNw9ChQ2FhYSF1lHyzdOlSeHh4wNjYGPXq1cP58+ffu36zZs3U30/vfmX1B/XAgQMhk8mwYMGCTF9PSUlBzZo1IZPJEBISol4eGhqa6XHOnj2rXmfkyJFYv349Hj58qPX71haLmzwUlagAAPjXL5XlOuPHj4erqysOHTqEmTNnwsCA3Z6ISFPr1q3x4sULPHz4EPPnz8cvv/yCKVOmaKyzePFidOjQAQ0bNsS5c+dw9epV+Pn5YeDAgRg5cqTGuhMmTICvry/q1q2LgwcP4vr165g7dy6uXLmCjRs3Ftj7UigU+bbvsLAw/Pbbb+jdu3eu9pOfGXNr+/btGDFiBKZMmYLg4GDUqFEDrVq1Ug8fkpndu3fjxYsX6q/r169DX18fXbp0ybDunj17cPbsWbi4uGS5v9GjR7/39aNHj2ocz9PTU/2anZ0dWrVqheXLl2fzHeeCKGZiYmIEABETE5Pn+y415jdRasxvYvr+G+plCQkJ4sSJExrrJScn5/mxiUhTUlKSuHnzpkhKShJCCKFSqURCSqokXyqVKtu5/f39RYcOHTSWffnll6JWrVrq52FhYcLQ0FCMGDEiw/aLFi0SAMTZs2eFEEKcO3dOABALFizI9Hhv3rzJMsuTJ0+En5+fKFGihDA1NRWenp7q/WaWc9iwYaJp06bq502bNhWDBw8Ww4YNE7a2tqJZs2aia9euwsfHR2M7hUIhbG1txfr164UQQiiVSjFr1izh4eEhjI2NRfXq1cWOHTuyzCmEEHPmzBF16tTRWBYZGSn8/PyEi4uLMDExER999JHYsmWLxjqZZRRCiGvXronWrVsLMzMz4eDgIHr06CFevXql3u7gwYOiYcOGwsrKStjY2Ii2bduK+/fvvzdjbnl5eYnBgwernyuVSuHi4iICAgKyvY/58+cLCwsLER8fr7H86dOnwtXVVVy/fl2UKlVKzJ8/P8O2Bw4cEJUqVRI3btwQAMTly5fVrz169CjDssysX79euLm5Zfn6f39u36XN5zebDfKQTAYIATSraA8AuHnzJnx8fPDgwQOcO3cO1atXBwAYGRlJGZOoWEpKVaLK5MOSHPvm9FYwlefs1+3169fxzz//oFSpf1uEd+7cidTU1AwtNADw9ddfY/z48di6dSvq1auHzZs3w9zcHN98802m+7e2ts50eXx8PJo2bQpXV1fs27cPTk5OCA4OhkqlynT9rKxfvx6DBg3C6dOnAaTfJdqlSxfEx8erR6E9fPgwEhMT8cUXXwAAAgICsGnTJqxYsQLly5fH33//jR49esDe3h5NmzbN9DgnT55EnTp1NJYlJyfD09MTY8aMgaWlJX7//Xf07NkTZcuWhZeXV5YZo6Oj0aJFC/Tv3x/z589HUlISxowZAx8fH/z5558AgISEBIwYMQLVq1dHfHw8Jk+ejC+++AIhISFZDj8wa9YszJo1673n6+bNmyhZsmSG5QqFApcuXcK4cePUy/T09ODt7a2efzA71qxZAz8/P5iZmamXqVQq9OzZE6NGjULVqlUz3S4iIgIDBgzA3r173ztuVPv27ZGcnIwKFSpg9OjRaN++vcbrXl5eePr0KUJDQ+Hh4ZHt3NoqFMXN0qVLMWfOHISHh6NGjRpYvHixxjfef+3YsQOTJk1CaGgoypcvj9mzZ6NNmzYFmDhz/x+mBhUdLbBu3ToMHjwYSUlJcHJyQmxsrLThiKjI+O2332Bubo60tDSkpKRAT08PS5YsUb9+9+5dWFlZwdnZOcO2crkcZcqUwd27dwEA9+7dQ5kyZWBoqN18d1u2bMGrV69w4cIF2NjYAADKlSun9XspX748fvrpJ/XzsmXLwszMDHv27EHPnj3Vx2rfvj0sLCyQkpKCWbNm4ejRo6hfvz4AoEyZMjh16hR++eWXLIubx48fZyhuXF1dNQrAoUOH4vDhwwgKCtL4jPlvxhkzZqBWrVoahcjatWvh7u6Ou3fvokKFChnm+lu7di3s7e1x8+ZNfPTRR5lmHDhwIHx8fN57vrK65BMZGQmlUglHR0eN5Y6Ojrh9+/Z79/nW+fPncf36daxZs0Zj+ezZs2FgYIBvv/020+2EEOjduzcGDhyIOnXqIDQ0NMM65ubmmDt3Lho2bAg9PT3s2rULHTt2xN69ezUKnLfv7/Hjx7pd3Ly9hrhixQrUq1cPCxYsQKtWrXDnzh04OGScWfuff/5B165dERAQgM8//xxbtmxBx44dERwcnOU3VEGIjE8BAKgUSfjum/7YunkzAOCTTz7Bxo0bM3xDElHBMjHUx83prSQ7tjaaN2+O5cuXIyEhAfPnz4eBgUGOJ84Vb//q0lJISAhq1aqlLmxy6t0+FwBgYGAAHx8fbN68GT179kRCQgJ+/fVXbNu2DUB6y05iYiI++eQTje0UCgVq1aqV5XGSkpJgbGyssUypVGLWrFkICgrCs2fPoFAokJKSkqHl4b8Zr1y5guPHj2c6v9GDBw9QoUIF3Lt3D5MnT8a5c+cQGRmpbtEKCwvL8rPIxsYm1+czN9asWYNq1appFHaXLl3CwoULERwcnOUAeosXL0ZcXJxGq9F/2dnZYcSIEerndevWxfPnzzFnzhyN4sbExAQA8n2+N8mLm3nz5mHAgAHo06cPAGDFihX4/fffsXbtWowdOzbD+gsXLkTr1q0xatQoAMAPP/yAI0eOYMmSJVixYkWBZn9XYooSipeP8OrX2dga9RR6enqYPn06xo0bxxFSiQoBmUyW40tDBc3MzEzdSrJ27VrUqFEDa9asQb9+/QAAFSpUQExMDJ4/f57hL32FQoEHDx6gefPm6nVPnTqF1NRUrVpv3n4IZUVPTy9D4ZSamprpe/mv7t27o2nTpnj58iWOHDkCExMTtG7dGkD65TAA+P333+Hq6qqx3fsu6dvZ2eHNG83hOObMmYOFCxdiwYIFqFatGszMzPDdd99l6DT834zx8fFo164dZs+eneE4b1vL2rVrh1KlSmHVqlVwcXGBSqXCRx999N4Oybm5LGVnZwd9fX1ERERoLI+IiICTk9N79wmkX0bbtm0bpk+frrH85MmTePnypcYxlUolvv/+eyxYsAChoaH4888/cebMmQznv06dOujevTvWr1+f6THr1auHI0eOaCx7e3eevb39BzPnhqSfum+vIXp7e6uXfega4pkzZzTWB4BWrVpluX5KSgpiY2M1vvLDrfBYJN47i7Sop3BxccHx48cxYcIEFjZElCt6enoYP348Jk6ciKSkJABAp06dYGhoiLlz52ZYf8WKFUhISEDXrl0BAN26dUN8fDyWLVuW6f6jo6MzXV69enWEhIRkeau4vb09Xrx4obHs3VuD36dBgwZwd3fH9u3bsXnzZnTp0kVdeFWpUgVGRkYICwtDuXLlNL7c3d2z3GetWrVw8+ZNjWWnT59Ghw4d0KNHD9SoUUPjct371K5dGzdu3ICHh0eGDGZmZnj9+jXu3LmDiRMnomXLlqhcuXKGwiozAwcOREhIyHu/srosJZfL4enpiWPHjqmXqVQqHDt2TH357n127NiBlJQU9OjRQ2N5z549cfXq1QwZRo0ahcOH0/uoLVq0CFeuXFG/fuDAAQDpV15mzpyZ5TFDQkIyXDq9fv06DA0Ns+zbk1ck/TMmJ9cQw8PDM10/PDw80/UDAgIwbdq0vAn8Hg4WRnBo7IdKDibYv2JWvlelRFR8dOnSBaNGjcLSpUsxcuRIlCxZEj/99BO+//57GBsbo2fPnjA0NMSvv/6K8ePH4/vvv0e9evUApP/1PHr0aHz//fd49uwZvvjiC7i4uOD+/ftYsWIFGjVqhGHDhmU4ZteuXTFr1ix07NgRAQEBcHZ2xuXLl+Hi4oL69eujRYsWmDNnDjZs2ID69etj06ZNuH79+nsvHb2rW7duWLFiBe7evYvjx4+rl1tYWGDkyJEYPnw4VCoVGjVqhJiYGJw+fRqWlpbw9/fPdH+tWrVC//79oVQq1RMuli9fHjt37sQ///yDEiVKYN68eYiIiECVKlXem23w4MFYtWoVunbtitGjR8PGxgb379/Htm3bsHr1apQoUQK2trZYuXIlnJ2dERYWlumVhv/K7WWpESNGwN/fH3Xq1IGXlxcWLFiAhIQE9ZUPAOjVqxdcXV0REBCgse2aNWvQsWNH2Nraaiy3tbXNsMzQ0BBOTk6oWLEiAGRoSXp7ua5s2bLqcdrWr18PuVyu/v/fvXs31q5di9WrV2tse/LkSTRu3PiDLYO59sH7qfLRs2fPBADxzz//aCwfNWqU8PLyynQbQ0PDDLfyLV26VDg4OGS6fnJysoiJiVF/PXnyJN9uBSeiwuN9t5QWZpndYi2EEAEBAcLe3l7jFt5ff/1VNG7cWJiZmQljY2Ph6ekp1q5dm+l+t2/fLpo0aSIsLCyEmZmZqF69upg+ffp7bwUPDQ0VnTp1EpaWlsLU1FTUqVNHnDt3Tv365MmThaOjo7CyshLDhw8XQ4YMyXAr+LBhwzLd982bNwUAUapUqQy3yqtUKrFgwQJRsWJFYWhoKOzt7UWrVq3EX3/9lWXW1NRU4eLiIg4dOqRe9vr1a9GhQwdhbm4uHBwcxMSJE0WvXr00zm9WGe/evSu++OILYW1tLUxMTESlSpXEd999p8565MgRUblyZWFkZCSqV68uTpw4IQCIPXv2ZJkxLyxevFiULFlSyOVy4eXlpb41/9334+/vr7Hs9u3bAoD4448/snWMrG4Ffyuz274DAwNF5cqVhampqbC0tBReXl6Z3r5fsWJFsXXr1iz3nVe3gsuEyGFvszygUChgamqKnTt3omPHjurl/v7+iI6Oxq+//pphm5IlS2LEiBH47rvv1MumTJmCvXv34sqVKx88ZmxsLKysrBATEwNLS8u8eBtEVAglJyfj0aNHKF26dIaOpqSbli5din379qkvp1DhcvDgQXz//fe4evVqlgPYvu/nVpvPb0k7hOTkGmL9+vU11geAI0eOZOuaIxER6a6vv/4aTZo04dxShVRCQgLWrVtXICPzS37rwIeuIf73+uGwYcPQtGlTzJ07F23btsW2bdtw8eJFrFy5Usq3QUREEjMwMMCECROkjkFZ6Ny5c4EdS/LixtfXF69evcLkyZMRHh6OmjVr4tChQ+pOw2FhYRp3HDVo0ABbtmzBxIkTMX78eJQvXx579+6VdIwbIiIiKjwk7XMjBfa5ISoe2OeGqOjRiT43RET5rZj9/UZUpOXVzyuLGyLSSW8HhcvvYd6JKO+8HeH57VhFOSV5nxsiovygr68Pa2trvHz5EgBgamqa5dw5RCQ9lUqFV69ewdTUNNd3VLG4ISKd9XbOnbcFDhEVbnp6eihZsmSu/xBhcUNEOksmk8HZ2RkODg6ZTupIRIWLXC7PkzkZWdwQkc7T19fP9TV8Iio62KGYiIiIdAqLGyIiItIpLG6IiIhIpxS7PjdvBwiKjY2VOAkRERFl19vP7ewM9Ffsipu3s8W6u7tLnISIiIi0FRcXBysrq/euU+zmllKpVHj+/DksLCzyfECv2NhYuLu748mTJ5y3Kh/xPBcMnueCwfNccHiuC0Z+nWchBOLi4uDi4vLB28WLXcuNnp4e3Nzc8vUYlpaW/MEpADzPBYPnuWDwPBccnuuCkR/n+UMtNm+xQzERERHpFBY3REREpFNY3OQhIyMjTJkyBUZGRlJH0Wk8zwWD57lg8DwXHJ7rglEYznOx61BMREREuo0tN0RERKRTWNwQERGRTmFxQ0RERDqFxQ0RERHpFBY3Wlq6dCk8PDxgbGyMevXq4fz58+9df8eOHahUqRKMjY1RrVo1HDhwoICSFm3anOdVq1ahcePGKFGiBEqUKAFvb+8P/r9QOm2/n9/atm0bZDIZOnbsmL8BdYS25zk6OhqDBw+Gs7MzjIyMUKFCBf7uyAZtz/OCBQtQsWJFmJiYwN3dHcOHD0dycnIBpS2a/v77b7Rr1w4uLi6QyWTYu3fvB7c5ceIEateuDSMjI5QrVw6BgYH5nhOCsm3btm1CLpeLtWvXihs3bogBAwYIa2trERERken6p0+fFvr6+uKnn34SN2/eFBMnThSGhobi2rVrBZy8aNH2PHfr1k0sXbpUXL58Wdy6dUv07t1bWFlZiadPnxZw8qJF2/P81qNHj4Srq6to3Lix6NChQ8GELcK0Pc8pKSmiTp06ok2bNuLUqVPi0aNH4sSJEyIkJKSAkxct2p7nzZs3CyMjI7F582bx6NEjcfjwYeHs7CyGDx9ewMmLlgMHDogJEyaI3bt3CwBiz549713/4cOHwtTUVIwYMULcvHlTLF68WOjr64tDhw7la04WN1rw8vISgwcPVj9XKpXCxcVFBAQEZLq+j4+PaNu2rcayevXqia+//jpfcxZ12p7n/0pLSxMWFhZi/fr1+RVRJ+TkPKelpYkGDRqI1atXC39/fxY32aDteV6+fLkoU6aMUCgUBRVRJ2h7ngcPHixatGihsWzEiBGiYcOG+ZpTl2SnuBk9erSoWrWqxjJfX1/RqlWrfEwmBC9LZZNCocClS5fg7e2tXqanpwdvb2+cOXMm023OnDmjsT4AtGrVKsv1KWfn+b8SExORmpoKGxub/IpZ5OX0PE+fPh0ODg7o169fQcQs8nJynvft24f69etj8ODBcHR0xEcffYRZs2ZBqVQWVOwiJyfnuUGDBrh06ZL60tXDhw9x4MABtGnTpkAyFxdSfQ4Wu4kzcyoyMhJKpRKOjo4ayx0dHXH79u1MtwkPD890/fDw8HzLWdTl5Dz/15gxY+Di4pLhB4r+lZPzfOrUKaxZswYhISEFkFA35OQ8P3z4EH/++Se6d++OAwcO4P79+/jmm2+QmpqKKVOmFETsIicn57lbt26IjIxEo0aNIIRAWloaBg4ciPHjxxdE5GIjq8/B2NhYJCUlwcTEJF+Oy5Yb0ik//vgjtm3bhj179sDY2FjqODojLi4OPXv2xKpVq2BnZyd1HJ2mUqng4OCAlStXwtPTE76+vpgwYQJWrFghdTSdcuLECcyaNQvLli1DcHAwdu/ejd9//x0//PCD1NEoD7DlJpvs7Oygr6+PiIgIjeURERFwcnLKdBsnJyet1qecnee3fv75Z/z44484evQoqlevnp8xizxtz/ODBw8QGhqKdu3aqZepVCoAgIGBAe7cuYOyZcvmb+giKCffz87OzjA0NIS+vr56WeXKlREeHg6FQgG5XJ6vmYuinJznSZMmoWfPnujfvz8AoFq1akhISMBXX32FCRMmQE+Pf/vnhaw+By0tLfOt1QZgy022yeVyeHp64tixY+plKpUKx44dQ/369TPdpn79+hrrA8CRI0eyXJ9ydp4B4KeffsIPP/yAQ4cOoU6dOgURtUjT9jxXqlQJ165dQ0hIiPqrffv2aN68OUJCQuDu7l6Q8YuMnHw/N2zYEPfv31cXjwBw9+5dODs7s7DJQk7Oc2JiYoYC5m1BKTjlYp6R7HMwX7sr65ht27YJIyMjERgYKG7evCm++uorYW1tLcLDw4UQQvTs2VOMHTtWvf7p06eFgYGB+Pnnn8WtW7fElClTeCt4Nmh7nn/88Uchl8vFzp07xYsXL9RfcXFxUr2FIkHb8/xfvFsqe7Q9z2FhYcLCwkIMGTJE3LlzR/z222/CwcFBzJgxQ6q3UCRoe56nTJkiLCwsxNatW8XDhw/FH3/8IcqWLSt8fHykegtFQlxcnLh8+bK4fPmyACDmzZsnLl++LB4/fiyEEGLs2LGiZ8+e6vXf3go+atQocevWLbF06VLeCl4YLV68WJQsWVLI5XLh5eUlzp49q36tadOmwt/fX2P9oKAgUaFCBSGXy0XVqlXF77//XsCJiyZtznOpUqUEgAxfU6ZMKfjgRYy238/vYnGTfdqe53/++UfUq1dPGBkZiTJlyoiZM2eKtLS0Ak5d9GhznlNTU8XUqVNF2bJlhbGxsXB3dxfffPONePPmTcEHL0KOHz+e6e/bt+fW399fNG3aNMM2NWvWFHK5XJQpU0asW7cu33PKhGD7GxEREekO9rkhIiIincLihoiIiHQKixsiIiLSKSxuiIiISKewuCEiIiKdwuKGiIiIdAqLGyIiItIpLG6ISENgYCCsra2ljpFjMpkMe/fufe86vXv3RseOHQskDxEVPBY3RDqod+/ekMlkGb7u378vdTQEBgaq8+jp6cHNzQ19+vTBy5cv82T/L168wGeffQYACA0NhUwmQ0hIiMY6CxcuRGBgYJ4cLytTp05Vv099fX24u7vjq6++QlRUlFb7YSFGpD3OCk6ko1q3bo1169ZpLLO3t5cojSZLS0vcuXMHKpUKV65cQZ8+ffD8+XMcPnw41/v+0OzxAGBlZZXr42RH1apVcfToUSiVSty6dQt9+/ZFTEwMtm/fXiDHJyqu2HJDpKOMjIzg5OSk8aWvr4958+ahWrVqMDMzg7u7O7755hvEx8dnuZ8rV66gefPmsLCwgKWlJTw9PXHx4kX166dOnULjxo1hYmICd3d3fPvtt0hISHhvNplMBicnJ7i4uOCzzz7Dt99+i6NHjyIpKQkqlQrTp0+Hm5sbjIyMULNmTRw6dEi9rUKhwJAhQ+Ds7AxjY2OUKlUKAQEBGvt+e1mqdOnSAIBatWpBJpOhWbNmADRbQ1auXAkXFxeNWbgBoEOHDujbt6/6+a+//oratWvD2NgYZcqUwbRp05CWlvbe92lgYAAnJye4urrC29sbXbp0wZEjR9SvK5VK9OvXD6VLl4aJiQkqVqyIhQsXql+fOnUq1q9fj19//VXdCnTixAkAwJMnT+Dj4wNra2vY2NigQ4cOCA0NfW8eouKCxQ1RMaOnp4dFixbhxo0bWL9+Pf7880+MHj06y/W7d+8ONzc3XLhwAZcuXcLYsWNhaGgIAHjw4AFat26NTp064erVq9i+fTtOnTqFIUOGaJXJxMQEKpUKaWlpWLhwIebOnYuff/4ZV69eRatWrdC+fXvcu3cPALBo0SLs27cPQUFBuHPnDjZv3gwPD49M93v+/HkAwNGjR/HixQvs3r07wzpdunTB69evcfz4cfWyqKgoHDp0CN27dwcAnDx5Er169cKwYcNw8+ZN/PLLLwgMDMTMmTOz/R5DQ0Nx+PBhyOVy9TKVSgU3Nzfs2LEDN2/exOTJkzF+/HgEBQUBAEaOHAkfHx+0bt0aL168wIsXL9CgQQOkpqaiVatWsLCwwMmTJ3H69GmYm5ujdevWUCgU2c5EpLPyfWpOIipw/v7+Ql9fX5iZmam/OnfunOm6O3bsELa2turn69atE1ZWVurnFhYWIjAwMNNt+/XrJ7766iuNZSdPnhR6enoiKSkp023+u/+7d++KChUqiDp16gghhHBxcREzZ87U2KZu3brim2++EUIIMXToUNGiRQuhUqky3T8AsWfPHiGEEI8ePRIAxOXLlzXW+e+M5h06dBB9+/ZVP//ll1+Ei4uLUCqVQgghWrZsKWbNmqWxj40bNwpnZ+dMMwghxJQpU4Senp4wMzMTxsbG6tmT582bl+U2QggxePBg0alTpyyzvj12xYoVNc5BSkqKMDExEYcPH37v/omKA/a5IdJRzZs3x/Lly9XPzczMAKS3YgQEBOD27duIjY1FWloakpOTkZiYCFNT0wz7GTFiBPr374+NGzeqL62ULVsWQPolq6tXr2Lz5s3q9YUQUKlUePToESpXrpxptpiYGJibm0OlUiE5ORmNGjXC6tWrERsbi+fPn6Nhw4Ya6zds2BBXrlwBkH5J6ZNPPkHFihXRunVrfP755/j0009zda66d++OAQMGYNmyZTAyMsLmzZvh5+cHPT099fs8ffq0RkuNUql873kDgIoVK2Lfvn1ITk7Gpk2bEBISgqFDh2qss3TpUqxduxZhYWFISkqCQqFAzZo135v3ypUruH//PiwsLDSWJycn48GDBzk4A0S6hcUNkY4yMzNDuXLlNJaFhobi888/x6BBgzBz5kzY2Njg1KlT6NevHxQKRaYf0lOnTkW3bt3w+++/4+DBg5gyZQq2bduGL774AvHx8fj666/x7bffZtiuZMmSWWazsLBAcHAw9PT04OzsDBMTEwBAbGzsB99X7dq18ejRIxw8eBBHjx6Fj48PvL29sXPnzg9um5V27dpBCIHff/8ddevWxcmTJzF//nz16/Hx8Zg2bRq+/PLLDNsaGxtnuV+5XK7+P/jxxx/Rtm1bTJs2DT/88AMAYNu2bRg5ciTmzp2L+vXrw8LCAnPmzMG5c+femzc+Ph6enp4aReVbhaXTOJGUWNwQFSOXLl2CSqXC3Llz1a0Sb/t3vE+FChVQoUIFDB8+HF27dsW6devwxRdfoHbt2rh582aGIupD9PT0Mt3G0tISLi4uOH36NJo2bapefvr0aXh5eWms5+vrC19fX3Tu3BmtW7dGVFQUbGxsNPb3tn+LUql8bx5jY2N8+eWX2Lx5M+7fv4+KFSuidu3a6tdr166NO3fuaP0+/2vixIlo0aIFBg0apH6fDRo0wDfffKNe578tL3K5PEP+2rVrY/v27XBwcIClpWWuMhHpInYoJipGypUrh9TUVCxevBgPHz7Exo0bsWLFiizXT0pKwpAhQ3DixAk8fvwYp0+fxoULF9SXm8aMGYN//vkHQ4YMQUhICO7du4dff/1V6w7F7xo1ahRmz56N7du3486dOxg7dixCQkIwbNgwAMC8efOwdetW3L59G3fv3sWOHTvg5OSU6cCDDg4OMDExwaFDhxAREYGYmJgsj9u9e3f8/vvvWLt2rboj8VuTJ0/Ghg0bMG3aNNy4cQO3bt3Ctm3bMHHiRK3eW/369VG9enXMmjULAFC+fHlcvHgRhw8fxt27dzFp0iRcuHBBYxsPDw9cvXoVd+7cQWRkJFJTU9G9e3fY2dmhQ4cOOHnyJB49eoQTJ07g22+/xdOnT7XKRKSTpO70Q0R5L7NOqG/NmzdPODs7CxMTE9GqVSuxYcMGAUC8efNGCKHZ4TclJUX4+fkJd3d3IZfLhYuLixgyZIhGZ+Hz58+LTz75RJibmwszMzNRvXr1DB2C3/XfDsX/pVQqxdSpU4Wrq6swNDQUNWrUEAcPHlS/vnLlSlGzZk1hZmYmLC0tRcuWLUVwcLD6dbzToVgIIVatWiXc3d2Fnp6eaNq0aZbnR6lUCmdnZwFAPHjwIEOuQ4cOiQYNGggTExNhaWkpvLy8xMqVK7N8H1OmTBE1atTIsHzr1q3CyMhIhIWFieTkZNG7d29hZWUlrK2txaBBg8TYsWM1tnv58qX6/AIQx48fF0II8eLFC9GrVy9hZ2cnjIyMRJkyZcSAAQNETExMlpmIiguZEEJIW14RERER5R1eliIiIiKdwuKGiIiIdAqLGyIiItIpLG6IiIhIp7C4ISIiIp3C4oaIiIh0CosbIiIi0iksboiIiEinsLghIiIincLihoiIiHQKixsiIiLSKSxuiIiISKf8DwKa12wA9V6TAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize performance metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Predict probabilities and class labels for the test set\n",
    "y_pred_prob = model_phaz3.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
